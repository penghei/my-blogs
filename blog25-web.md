---
title: 网络知识学习总结
date: 2021-12-02 12:19:49
tags: 日常学习
cover: /img/web.png
categories: 原理
sticky: 6
---

# 网络基础知识

## 协议间关系

![协议关系.jpg](https://i.loli.net/2021/12/02/Uwe2Sb3oAJZKGVq.jpg)

## 链接/超链接

> 网站的三大支柱：
>
> - URL, 跟踪 Web 文档的地址系统
> - HTTP, 一个传输协议，以便在给定 URL 时查找文档
> - HTML, 允许嵌入超链接的文档格式

链接可以将任何文本与 URL 相关联，因此用户只要激活链接就可以到达目标文档。
链接的类型有：

- 内链：网页内的链接，用于网页里面的变化，比如滚动条滚动
- 外链：网页到另一个网页的链接
- 传入链接：从其他人的网页链接到你的网页的链接。

## URL

> URI 和 URL
> ![](https://pic.imgdb.cn/item/623429625baa1a80abfeda20.jpg)
> 统一资源标志符 URI 就是在某一规则下能把一个资源独一无二地标识出来的**字符串**。URI 是唯一的，一个资源对应一个 URI，且只能通过该 URI 定位该资源
> URI 分为 URL 和 URN，这两个是 URI 的一种形式：即，URL 通过标识位置的形式表示资源，同样起到了 URI 的作用，所以 URL 是 URI 的子集，URL 就是用定位的方式实现的 URI。URN 则是用资源名标识，不过不常用。

URL 的组成：
![](https://pic.imgdb.cn/item/623426a85baa1a80abfcb591.jpg)

```
http://www.example.com:80/path/to/myfile.html?key1=value1&key2=value2#SomewhereInTheDocument
```

1. `http://` ，超文本传输协议，它表明了浏览器必须使用何种协议，也可是 HTTPS；当然还可以是 `file://` 文件协议，或者邮箱协议等
2. `www.example.com` 是域名，这个也可以用ip地址代替
3. `:80`是端口。IP 地址与网络服务的关系是一对多的，所以需要表示用于访问 Web 服务器上的资源的技术“门”。如果 Web 服务器使用 HTTP 协议的标准端口（HTTP 为 80，HTTPS 为 443）来授予其资源的访问权限，则通常会被忽略。否则是强制性的。一般 80 端口就是网络服务器，如果你自己想有个网站，就需要通过 80 端口来向外展示
4. `/path/to/myfile.html `是文件或资源位于服务器上的路径（服务器也是一台电脑），也被称为路由；当然路由时一种抽象的路径
5. `?key1=value1&key2=value2`传输的参数，这种一般是 query 或者 parmas 参数
6. `#SomewhereInTheDocument` 是资源本身的另一部分的锚点. 锚点表示资源中的一种“书签”，给浏览器显示位于该“加书签”位置的内容的方向。

上面给出的 URL 是**绝对 URL**，因访问服务器没有上下文，所以要用绝对路径访问

### URL 的编码

URI 只能使用`ASCII`，其他编码方式不支持。因此可以直接表示在 URL 上的被称为“元字符”，也就是`ASCII`码中的全部字符。
其他编码的字符需要被转码，方式是将所有非 `ASCII` 码字符和界定符转为十六进制字节值，然后在前面加个%
详见 https://www.ruanyifeng.com/blog/2010/02/url_encoding.html

## 域名

域名需要从右到左阅读。

```
www.google.com
```

1. `.com`是顶级域名, 除了.com 之外还有一些顶级域名都有要求

- 地区的顶级域名，如.us，.fr，或.cn，可以要求必须提供给定语言的服务器或者托管在指定国家。
- 包含.gov 的顶级域名只能被政府部门使用。
- .edu 只能为教育或研究机构使用。

> 注: 域名用`.`分割,从右向左分别为顶级,二级,三级以及更后,上不设限,所以比如`www.a.b.c.d.e.f.com`,这里的 abcdef 都是不同级别的域名,每一级的域名控制它下一级域名的分配。每个域名内部是标签,标签在下面解释;

2. `google`是标签, 标签由 1 到 63 个大小写不敏感的字符组成，这些字符包含字母 A-z，数字 0-9，还有`-`号.一般都是小写字母,但可以是大写,都是一样

3. `www`表示提供资源的主机的名称，或者叫做服务器名。www虽然原本含义是万维网，但是通常大家习惯将他用作表示提供web服务的主机；如果有一个网站是`abc.www.com`，那www就成了一级域名。类似的服务器名还有blog、mail等

> 关于域名和主机名，大概有这样的区别：
>
> - 主机名 = 服务器名 + 域名。以`http://www.sina.com.cn/`为例，`sina.com.cn`是域名，`www`是提供服务的机器的名字（计算机名），计算机名+域名才是主机名，即`www.sina.com.cn`是主机名。
> - 域名只存在于公网，而主机名可以用于局域网。在局域网中每台主机用于互相区分，就有了主机名这个概念

## MIME

MIME(Multipurpose Internet Mail Extensions, 多用途互联网邮件扩展)。它首先用在电子邮件系统中，让邮件可以发任意类型的数据，这对于 HTTP 来说也是通用的。

因此，HTTP 从 MIME type 取了一部分来标记报文 body 部分的数据类型，这些类型体现在`Content-Type`这个字段; 接收端想要收到特定类型的数据，也可以用`Accept`字段。

具体而言，这两个字段的取值可以分为下面几类:

- text： `text/html`, `text/plain`, `text/css` 等
- image: `image/gif`, `image/jpeg`, `image/png` 等
- audio/video: `audio/mpeg`, `video/mp4` 等
- application: `application/json`, `application/javascript`, `application/pdf`, `application/octet-stream`

## 跨域

### 同源策略

**浏览器**遵循同源策略，非同源站点有这样一些限制:

- 不能读取和修改对方的 DOM
- 不读访问对方的 Cookie、IndexDB 和 LocalStorage
- 限制 XMLHttpRequest 、fetch等网络请求，即请求可以发出，但是不能接收到响应。

同源的条件：

- 主机名相同（域名+服务器名）
- 协议相同（http 和 https 不同）
- 端口相同

因为不符合同源策略的 ajax 请求会被禁用，因此就要想办法解决同源策略带来的限制。解决的方法有如下几种：

- CORS：跨域资源共享
- JSONP
- nginx 反向代理
- 配置代理
- nodejs 中间件

### CORS

CORS 其实是 W3C 的一个标准，全称是`跨域资源共享`；它需要浏览器和服务器的共同支持。

#### 简单请求

浏览器根据请求方法和请求头的特定字段，将请求做了一下分类，具体来说规则是这样，凡是满足下面条件的属于简单请求:

**简单请求**的范围:

1. 请求方法是以下三种方法之一：

- HEAD
- GET
- POST

2. HTTP 的头信息不超出以下几种字段：

- Accept
- Accept-Language
- Content-Language
- Last-Event-ID
- Content-Type：
  - application/x-www-form-urlencoded
  - multipart/form-data
  - text/plain

浏览器画了这样一个圈，在这个圈里面的就是简单请求, 圈外面的就是非简单请求，然后针对这两种不同的请求进行不同的处理。

---

对于简单请求，浏览器会在请求头加上`Origin`字段，用来说明请求来自于哪个`源`；
服务器拿到请求之后，会在响应头添加一些字段，主要有：

- `Access-Control-Allow-Origin`：如果`Origin`不在这个字段的范围中，浏览器就会将响应拦截。
  > Access-Control-Allow-Origin 字段设置为\*有什么问题？
  > 除了安全问题之外，还有一个问题是只要设置为\*就不能发送 cookies，即使`Access-Control-Allow-Credentials`为 true 也不行。
  > 如果需要发送，就必须指定明确的、与请求网页一致的域名。
- `Access-Control-Allow-Credentials`：表示是否允许发送 Cookie
  这一项的属性只能为 true，否则就不添加这个字段
- `Access-Control-Expose-Headers`：允许 xhr 可以拿到除了 6 个基本响应字段（`Cache-Control`、`Content-Language`、`Content-Type`、`Expires`、`Last-Modified`和`Pragma`）之外的其他字段。

这其中最主要的是第一个字段；如果设置的 origin 中包含当前请求，就可以不受同源策略的限制；如果设置为`*`，相当于完全不受同源策略影响，任何源都可以访问。

#### 非简单请求

非简单请求和简单请求处理的不同主要体现在两方面：

- 预检请求
- 响应字段

非简单请求发送之前会先发送一个预检请求，方法固定是`options`；会加上 Origin 源地址和 Host 目标地址。同时也会加上两个关键的字段:

- `Access-Control-Request-Method`， 列出 CORS 请求用到哪个 HTTP 方法
- `Access-Control-Request-Headers`，指定 CORS 请求将要加上什么请求头

预检请求会像这样：

```
OPTIONS / HTTP/1.1
Origin: 当前地址
Host: xxx.com
Access-Control-Request-Method: PUT
Access-Control-Request-Headers: X-Custom-Header
```

随后响应字段也会有所不同；响应字段除了响应预检请求本身，还有对 CORS 的相关字段：

```
HTTP/1.1 200 OK
Access-Control-Allow-Origin: *
Access-Control-Allow-Methods: GET, POST, PUT
Access-Control-Allow-Headers: X-Custom-Header
Access-Control-Allow-Credentials: true
Access-Control-Max-Age: 1728000
Content-Type: text/html; charset=utf-8
Content-Encoding: gzip
Content-Length: 0
```

其中有这样几个关键的响应头字段:

- `Access-Control-Allow-Origin`: 表示可以允许请求的源，可以填具体的源名，也可以填`*`表示允许任意源请求，和简单请求的该字段一样
- `Access-Control-Allow-Methods`: 表示允许的请求方法列表。
- `Access-Control-Allow-Credentials`: 同简单请求
- `Access-Control-Allow-Headers`: 表示允许发送的请求头字段
- `Access-Control-Max-Age`: 预检请求的有效期，在此期间，不用发出另外一条预检请求。

在预检请求的响应返回后：

- 如果请求不满足响应头的条件，则触发`XMLHttpRequest`的`onerror`，当然后面真正的 CORS 请求也不会发出去了。
- 如果满足条件，则会和简单请求一样，浏览器自动加上`Origin`字段，响应头返回`Access-Control-Allow-Origin`。

### JSONP

`XMLHttpRequest` 对象遵循同源政策，但是`<script>`标签不一样，它可以通过 src 填上目标地址从而发出 GET 请求，实现跨域请求并拿到响应。这也就是 JSONP 的原理。
基本原理：

```js
function callback(data) {
  console.log(data);
}
const script = document.createElement("script");
script.src = `http://example.com?callback=callback`;
document.body.appendChild(script);
```

简单实现如下：

```js
function jsonp({ url, params, callback }) {
  const script = document.createElement("script");
  const cbFnName = `JSONP_PADDING_${Math.random().toString().slice(2)}`;
  script.src = `${url}?${JSON.stringfy(params)}&callback=${cbFnName}`; // 这一步封装url还有更详细的操作，这里只是简单表示
  // 为了避免全局污染，使用一个随机函数名
  window[cbFnName] = callback; // 把回调插入window上，这里也可以直接定义一个全局函数
  document.body.appendChild(script);
}

jsonp({
  url: "http://localhost:8080",
  params: { id: 10000 },
  callback(data) {
    console.log("Data:", data);
  },
});
```

Promise 实现：

```js
/*封装jsonp*/
const jsonp = ({ url, params, callbackName }) => {
  //把params封装到url中
  const generateURL = () => {
    let dataStr = "";
    for (let key in params) {
      dataStr += `${key}=${params[key]}&`;
    }
    dataStr += `callback=${callbackName}`;
    return `${url}?${dataStr}`;
  };
  return new Promise((resolve, reject) => {
    // 初始化回调函数名称
    callbackName = callbackName || Math.random().toString.replace(",", "");
    // 创建 script 元素并加入到当前文档中
    let scriptEle = document.createElement("script");
    scriptEle.src = generateURL();
    document.body.appendChild(scriptEle);
    // 绑定到 window 上，为了后面调用
    window[callbackName] = (data) => {
      resolve(data);
      // script 执行完了，成为无用元素，需要清除
      document.body.removeChild(scriptEle);
    };
  });
};

/*使用*/
jsonp({
  url: "http://localhost:3000",
  params: {
    a: 1,
    b: 2,
  },
}).then((data) => {
  // 拿到数据进行处理
  console.log(data); // 数据包
});

/*服务端*/
let express = require("express");
let app = express();
app.get("/", function (req, res) {
  let { a, b, callback } = req.query;
  console.log(a); // 1
  console.log(b); // 2
  // 注意，返回给script标签，浏览器直接把这部分字符串执行；因此就相当于执行了一个全局定义的callback
  res.end(`${callback}('数据包')`);
});
app.listen(3000);
```

可以看到，JSONP 最大的优势在于兼容性好缺点也很明显，请求方法单一，只支持 GET 请求。

---

还有一种方法是显式添加`<script>`标签，然后通过回调的方式取出 script 中的数据：

把要获取的数据封装成一个 js 文件

```js
//weather.js
showWeather(
  JSON.parse({
    weather: "sunny",
    time: "2021-12-03 16:30",
  })
);
```

然后在 js 中的 script 标签获取

```html
<script src="/api/weather.js"></script>
<script>
  function showWeather(data) {
    console.log(data);
  }
</script>
```

### Nginx 反向代理

![](https://pic.imgdb.cn/item/6234574f5baa1a80ab235752.jpg)

- 正向代理帮助客户端访问客户端自己访问不到的服务器，然后将结果返回给客户端。
- 反向代理拿到客户端的请求，将请求转发给其他的服务器，主要的场景是维持服务器集群的负载均衡，换句话说，反向代理帮其它的服务器拿到请求，然后选择一个合适的服务器，将请求转交给它。

因此正向代理服务器是帮**客户端**做事情，而反向代理服务器是帮**其它的服务器**做事情。

Nginx 的配置原理很像一般脚手架提供的配置方法，即利用**服务器之间没有同源限制**，把代理服务器设置在和客户端同源的路由下，然后转发请求到服务器；收到响应后再转发回客户端。
比如这样的配置：

```
server {
  listen  80;
  server_name  client.com;
  location /api {
    proxy_pass server.com;
  }
}
```

Nginx 相当于起了一个跳板机，这个跳板机的域名也是`client.com`，让客户端首先访问 `client.com/api`，这当然没有跨域，然后 Nginx 服务器作为反向代理，将请求转发给`server.com`，当响应返回时又将响应给到客户端，这就完成整个跨域请求的过程。

### http-proxy-middleware

http-proxy-middleware 解决跨域的方案，是通过本地起了一个 node 代理服务器（`var httpProxy = require('http-proxy')`），通过代理服务器去请求目标服务器，然后返回请求结果。由于浏览器请求的是本地路径，所以不会有跨域问题。

这个中间件的使用有两个方式，一是在 nodejs 服务端设定该代理服务器，然后作为中间件的形式使用；

```js
// 中间代理服务器
const express = require("express");
const proxy = require("http-proxy-middleware");
const app = express();

app.use(
  "/",
  proxy({
    // 代理跨域目标接口
    target: "http://www.proxy2.com:8080",
    changeOrigin: true,
    // 修改响应头信息，实现跨域并允许带 cookie
    onProxyRes: function (proxyRes, req, res) {
      res.header("Access-Control-Allow-Origin", "http://localhost");
      res.header("Access-Control-Allow-Credentials", "true");
    },
    // 修改响应信息中的 cookie 域名
    cookieDomainRewrite: "localhost", // 可以为 false，表示不修改
  })
);
app.listen(3000);
```

还有一种形式是利用 webpack 的 devServer 配置项，在其中引入该代理服务器的配置。webpack 会把这个中间件用在配置本地启动的服务器上：

```js
module.exports = {
  //...
  devServer: {
    proxy: {
      "/api": {
        target: "http://localhost:3000",
        pathRewrite: { "^/api": "" },
        changeOrigin: true,
      },
    },
  },
};
```

## 网络模型

![](https://pic.imgdb.cn/item/623464365baa1a80ab2d7eee.png)

- 应用层 (application layer)：直接为应用进程提供服务。应用层协议定义的是应用进程间通讯和交互的规则，不同的应用有着不同的应用层协议，如 HTTP 协议（万维网服务）、FTP 协议（文件传输）、SMTP 协议（电子邮件）、DNS（域名查询）等。
  - 表示层：用于解决两个系统间交换信息的语法与语义问题，还有数据表示转化(转为主机无关编码)，加解密和压缩与解压缩功能。
  - 会话层：用于建立会话 SSL 等
- 传输层 (transport layer)：有时也译为运输层，它负责为两台主机中的进程提供通信服务。该层主要有以下两种协议：
  - 传输控制协议 (Transmission Control Protocol，TCP)：提供面向连接的、可靠的数据传输服务，数据传输的基本单位是报文段（segment）；
  - 用户数据报协议 (User Datagram Protocol，UDP)：提供无连接的、尽最大努力的数据传输服务，但不保证数据传输的可靠性，数据传输的基本单位是用户数据报。
- 网络层 (internet layer)：有时也译为网际层，它负责为两台主机提供通信服务，并通过选择合适的路由将数据传递到目标主机。
- 数据链路层 (data link layer)：负责将网络层交下来的 IP 数据报封装成帧，并在链路的两个相邻节点间传送帧，每一帧都包含数据和必要的控制信息（如同步信息、地址信息、差错控制等）。
- 物理层 (physical Layer)：确保数据可以在各种物理媒介上进行传输，为数据的传输提供可靠的环境。

![](https://pic.imgdb.cn/item/623464f65baa1a80ab2dcd4e.jpg)

这张图更清晰展现了每一层的协议处在计算机的什么位置上：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/7.jpg)

## 鉴权校验相关

### Session

> 有关于 session/token/JWT 的更多解释可以看这里：https://mubu.com/doc/12i79Sq9hmP

![](https://pic1.imgdb.cn/item/634bfad916f2c2beb1870975.jpg)
是另一种 cookie，同时依赖于 cookie，但是存储在服务端，sessionId 会被存储到客户端的 cookie 中

- 用户第一次请求服务器的时候，服务器根据用户提交的相关信息，创建对应的 Session
- 请求返回时将此 Session 的唯一标识信息 SessionID 返回给浏览器
- 浏览器接收到服务器返回的 SessionID 信息后，会将此信息存入到 Cookie 中，同时 Cookie 记录此 SessionID 属于哪个域名
- 当用户第二次访问服务器的时候，请求会自动判断此域名下是否存在 Cookie 信息，如果存在自动将 Cookie 信息也发送给服务端，服务端会从 Cookie 中获取 SessionID，再根据 SessionID 查找对应的 Session 信息，如果没有找到说明用户没有登录或者登录失效，如果找到 Session 证明用户已经登录可执行后面操作。

> session 和 cookie 有什么区别:
> cookie 是 Web 服务器发送给浏览器的一块信息。浏览器会在本地文件中给每一个 Web 服务器存储 cookie。以后浏览器在给特定的 Web 服务器发请求的时候，同时会发送所有为该服务器存储的 cookie。下面列出了 session 和 cookie 的区别：
> 无论客户端浏览器做怎么样的设置，session 都应该能正常工作。客户端可以选择禁用 cookie，但是，session 仍然是能够工作的，因为客户端无法禁用服务端的 session。
> 在存储的数据量方面 session 和 cookies 也是不一样的。session 能够存储任意的 Java 对象，cookie 只能存储 String 类型的对象。

### Token（令牌）

#### Access Token

访问资源接口（API）时所需要的资源凭证，相当于展示证件才能进入或访问的过程
简单 token 的组成： uid(用户唯一的身份标识)、time(当前时间的时间戳)、sign（签名，token 的前几位以哈希算法压缩成的一定长度的十六进制字符串）
![accesstoken.png](https://i.loli.net/2021/12/02/EKhFUQzAP3vcjxa.png)

- 客户端每一次请求都需要携带 token，需要把 token 放到 HTTP 的 Header 里
- token 完全由应用管理，所以它可以避开同源策略
- 客户端收到 token 以后，会把它存储起来，比如放在 cookie 里或者 localStorage 里

#### Refresh Token

是一种延长 accesstoken 的方法，主要解决方法是：

- 如果 accesstoken 没过期，就正常使用
- 如果 accesstoken 过期，但 Refresh Token 没过期，就可以获取到新的 Token
- 如果都过期就需要重新登录
- Refresh Token 及过期时间是存储在服务器的数据库中，只有在申请新的 Acesss Token 时才会验证

### JWT

JSON Web Token（简称 JWT）是目前最流行的**跨域认证**解决方案。是一种认证授权机制。

JWT 的原理是，服务器认证以后，生成一个 JSON 对象，发回给用户，就像下面这样。

```json
{
  "姓名": "张三",
  "角色": "管理员",
  "到期时间": "2022年7月1日0点0分"
}
```

以后，用户与服务端通信的时候，都要发回这个 JSON 对象。服务器完全只靠这个对象认定用户身份。

实际上的jwt是经过Base64处理之后的，一个很长的字符串，通常包含有实际需要传递的数据。因此JWT可以一定程度上降低服务器查询数据库的次数。

session 是保存在服务端的，而 jwt 是保存在客户端的。
原理图：
![JWT.png](https://i.loli.net/2021/12/02/chSBlOHZ9dDIQiJ.png)
使用方式：

- 跨域的时候，可以把 JWT 放在 POST 请求的数据体里。
- 通过 URL 传输，比如`http://www.example.com/user?token=xxx`
- 放在 HTTP 请求头信息的 Authorization 字段里

缺点：

1. 安全性不好，因为 jwt 是明文传输的，并且经常需要从客户端发向服务端，不安全
2. 由于服务器不保存 session 状态，因此无法在使用过程中废止某个 token，或者更改 token 的权限。也就是说，一旦 JWT 签发了，在到期之前就会始终有效，除非服务器部署额外的逻辑。

### cookie

cookie 的详细解释可以看这篇文章:https://juejin.cn/post/6844904073934667790

> HTTP Cookie（也叫 Web Cookie 或浏览器 Cookie）是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。通常，它用于告知服务端两个请求是否来自同一浏览器，如保持用户的登录状态。Cookie 使基于无状态的 HTTP 协议记录稳定的状态信息成为了可能。

因此 cookie 的主要工作方式是:在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。

- 创建方式

服务器在响应头里添加`Set-Cookie`选项,比如这样

```
HTTP/1.0 200 OK
Content-type: text/html
Set-Cookie: yummy_cookie=choco
Set-Cookie: tasty_cookie=strawberry
```

js 也可以直接通过`document.cookie`来读写 cookie

#### cookie的跨域问题

cookie受到同源策略（CORS）的限制。如果两个网站不同源，那就不能共享cookie。至于cookie怎么跨域访问，在上面cors中说过了，主要通过HTTP头的`Access-Control-Allow-Credentials`可以控制跨域请求时的cookie发送与否，配合`XMLHttpRequest.withCredentials`设置为true，就可以在发送跨域请求时携带cookie。

cookie可以通过设置Domain来允许子域名访问，也可以设置SameSite控制从一个页面跳转到另一个时能不能共享cookie。

和cookie一样，localstorage也会收到同源限制。不同源的localstorage和sessionstorage不能访问；如果同源的不同页面可以共享localstorage，但不能共享
sessionstorage/localstorage的同源限制可以通过postMessage解决。

#### 第三方cookie

第三方cookie是建立在别的域名上的cookie，而不是你当前访问的域名（地址栏中的）。

比如：广告网络商就是最常见的第三方 cookies 的来源，他们用它们在多个网站上追踪用户的行为，当然这些活动可以用来调整广告。此外图像、 JavaScript 和 iframe 通常也会导致第三方 cookies 的生成。

解释一下广告是如何精准投放的。以百度联盟为例：使用百度的时候，会把你的此次搜索保存到你的cookie中，并且分配这个浏览器唯一可标识的ID号，当打开某影视的时候，该页的广告模块就向第三方，也就是广告服务商的服务器去请求百度保存在你的浏览器的cookie，然后就可以知道你最近浏览或者搜索过哪些商品，返回给你相关的广告。

在这个过程中，某影视访问的并不是由他自己设置的cookie，而是由第三方（百度）在你浏览器中设置的cookie。这时这两个网站明显是跨站且跨域的；对于这种访问的限制，就要说到cookie的samesite属性。

---

再举个例子，以CSRF攻击为例。比如有一个银行网站A和恶意网站B。
1. 银行网站A登录后在浏览器留下cookie
2. 在cookie没有过期的前提下，用户进入恶意网站B，B中伪造了一个表单，向A的服务器发送了一个请求

这时cookie并不是B留下的，但B网站向A服务器发送请求时，浏览器也带上了cookie，这时候我们就可以说，**浏览器从B网站向A服务器发送了cookie**。
B网站和A网站是跨站关系，而B网站这时就是第三方

#### 跨站和跨域

cookie中有一个samesite属性，这个属性用于控制跨站时的cookie发送。

跨站和跨域完全不一样。一般来说，同源策略的限制比较严格，但是跨站的限制稍小一些；只要两个url的**顶级域名+二级域名相同**，就可以被视作同站。

比如`www.abc.com`和`blog.abc.com`就被视作同站，但他们显然不同源

同理，`www.abc.com`和`www.def.com`就被视作跨站，因为二级域名不一样。

当前谷歌浏览器对samesite的默认值是lax，表示只允许一部分的跨站请求会发送cookie，包括a标签链接、预加载和get请求这三种。剩下情况中如果想跨站发送浏览器存储的cookie（即发送第三方cookie）就需要设置samesite为none。

比如上面说的第三方广告的形式，如果广告商想获取百度在你浏览器中存储的cookie，百度在设置该cookie时就应该设置samesite为none，这样才可以由其他网站访问并发送该cookie到自己的服务器上。

#### cookie 属性

- 名称: 表示该 cookie 的名字,一般常用`_`开头表示一些身份信息或 id 等
- 值: 就是 cookie 的值,可以是任意ASCII字符
- Domain: 限制访问域名,不设置就是都可以访问。domain设置的域名下的子域名都可以访问，比如设置了`test.com`，那么其下的`child.test.com`也可访问。
- Path: 主机下哪些路径可以访问,比如登录路径访问,就可以设置为`/login`。同样也是会匹配子路径
- SameSite：用于判断跨站时是否发送 cookie。samesite有三个值：
  - Strict：最严格，跨站完全不允许发送cookie
  - Lax：![](https://pic.imgdb.cn/item/629df38c094754312972cc14.jpg)
  - None：都可以发送，前提是必须同时设置Secure属性
- Expires/Max-Age: 生命周期,定义 Cookie 的有效时间
- HttpOnly:为避免跨域脚本 (XSS) 攻击，通过 JavaScript 的 Document.cookie API 无法访问带有 HttpOnly 标记的 Cookie，它们只应该发送给服务端。
- Secure: 标记时只能通过 https 发给服务端


> 这里再解释一下samesite的意义
> 以上面的CSRF攻击的例子为例，B网站向A服务器请求时，如果cookie设置了lax，那么只有B网站上的a标签、link标签和get请求可以携带A网站的cookie，其他的都不能携带cookie。
> 这时如果A网站的关键操作都是用的Post，那么B网站就没法伪造一个携带cookie的请求，从而防范了csrf攻击。
> 
> 如果设置成strict，那么某些正常的请求会受到影响。比如一个合法的网站想获取你的搜素记录从而对你进行个性化推荐，但他无法通过任何方式获取到你的cookie，也就意味着它完全不能拿到你的个人信息，因此就不能对你进行个性化推荐等功能。


### OAuth

OAuth 就是一种授权机制。数据的所有者告诉系统，同意授权第三方应用进入系统，获取这些数据。系统从而产生一个短期的进入令牌（token），用来代替密码，供第三方应用使用。OAuth 在"客户端"与"服务提供商"之间，设置了一个授权层（authorization layer）。"客户端"不能直接登录"服务提供商"，只能登录授权层，以此将用户与客户端区分开来。"客户端"登录授权层所用的令牌（token），与用户的密码不同。用户可以在登录的时候，指定授权层令牌的权限范围和有效期。
![](https://obohe.com/i/2021/12/03/sf3lt0.png)
流程如下:

1. 用户打开客户端以后，客户端要求用户给予授权。
2. 用户同意给予客户端授权。
3. 客户端使用上一步获得的授权，向认证服务器申请令牌。
4. 认证服务器对客户端进行认证以后，确认无误，同意发放令牌。
5. 客户端使用令牌，向资源服务器申请获取资源。
6. 资源服务器确认令牌无误，同意向客户端开放资源。

### SSO

SSO(单点登录)指的是在多个应用系统中，只需登录一次，就可以访问其他相互信任的应用系统。
详细可以看这篇文章https://www.zhihu.com/question/35165725

# 应用层

应用层的任务是通过应用进程间的交互来完成特定网络应用。应用层协议定义的是应用进程（进程：主机中正在运行的程序）间的通信和交互的规则。对于不同的网络应用需要不同的应用层协议。应用层协议是应用到应用的协议，相应的，传输层是进程到进程，网络层是主机到主机。
应用层主要协议：

- HTTP
- SMTP
- FTP
- DNS，但是 DNS 更像是一个应用，服务于上面的协议。

## 模型

应用层的模型主要有两个：

1. C/S 模型，即客户端/服务器模型；服务器总是启动，等待客户端的请求连接并发回响应。Web 和电子邮件都是这种
2. P2P 模式，每一个主机既是客户端又是服务器，资源在主机间交换。

## HTTP

### 基本特点

超文本传输协议（HTTP，HyperText Transfer Protocol）是互联网上应用最为广泛的一种网络协议。所有的 WWW（万维网） 文件都必须遵守这个标准。

- HTTP 基于 TCP，要建立 HTTP 连接的进程需要通过 TCP 传输，因此是可靠数据传输，并且拥有拥塞控制等优化手段。
- HTTP 是无状态的协议，单靠 HTTP 的话，并不会记录之前的传输，如果再次请求将会再次发送（可以通过 HTTP 缓存解决）；同时也不会存储关于用户的任何信息
- HTTP 客户端进程默认位于 80 端口
- 请求--应答方式，一发一收连接
- 灵活可扩展，传输数据自由不限制，并且语义比较自由

### 持续和非持续连接

HTTP 默认采用持续连接，即客户端和服务器建立 TCP 连接后，会一直使用这条连接进行数据交互，直到没有数据传输或异常断开。在空闲期间，通常会使用`心跳数据包（Keep-Alive）`保持链路不断开。如果这条链接一段时间未使用，服务器就会关闭连接。在持续链接持续期间，不再需要额外的 TCP 握手、挥手，只需要进行数据传输；

可以采用非持续连接，每一次发送都需要建立和断开连接，具体步骤如下：

1. HTTP 客户端在 80 端口向服务器发起一个 TCP 连接
2. 三次握手连接建立后，通过 socket 向服务器发送 HTTP 请求报文
3. 服务器接受报文，返回响应报文
4. 服务器通知 TCP 断开连接
5. 客户端收到响应报文，TCP 经过四次挥手关闭连接。

持续链接实际上就是对第 3 步的扩充

### HTTP 报文

#### 请求报文

```
POST / HTTP1.1
Host:www.wrox.com
User-Agent:Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 2.0.50727; .NET CLR 3.0.04506.648; .NET CLR 3.5.21022)
Content-Type:application/x-www-form-urlencoded
Content-Length:40
Connection: Keep-Alive

name=Professional%20Ajax&publisher=Wiley
```

![request.png](https://i.loli.net/2021/12/02/geW1ol4FckqY7ty.png)

报文的第一行叫做请求行，后续叫做首部行（请求头）

1. 请求行，用来说明请求类型,要访问的资源以及所使用的 HTTP 版本。GET 说明请求类型为 GET,`/562f25980001b1b106000338.jpg`为要访问的资源，或者也可以是路由；最后一部分说明使用的是 HTTP1.1 版本。
2. 请求头部（首部行），紧接着请求行（即第一行）之后的部分，用来说明服务器要使用的附加信息。
3. 空行，请求头部后面的空行是必须的；即使第四部分的请求数据为空，也必须有空行。
4. 请求数据，也叫实体体，可以添加任意的其他数据，GET 请求没有这部分。

#### 响应报文

```
HTTP/1.1 200 OK
Date: Fri, 22 May 2009 06:07:21 GMT
Content-Type: text/html; charset=UTF-8

<html>
      <head></head>
      <body>
            <!--body goes here-->
      </body>
</html>
```

1. 状态行，由 HTTP 协议版本号、状态码、状态消息三部分组成。第一行为状态行，`HTTP/1.1`表明 HTTP 版本为 1.1 版本，状态码为 200，状态消息为（ok）
2. 消息报头（首部行/响应头），用来说明客户端要使用的一些附加信息
3. 空行，消息报头后面的空行是必须的
4. 响应正文（实体体），服务器返回给客户端的文本信息。空行后面的 html 部分为响应正文。

### HTTP 字段

http1.1 的字段主要有 47 个，按照分类主要有 4 类：

1. 通用首部字段，常见的有：

- `Connection` 连接管理、逐条首部
- `Upgrade` 升级为其他协议
- `Cache-Control` 缓存控制，即代替`Expires`字段的缓存控制字段

2. 请求首部字段，包括 Accept 系列字段，以及`User-Agent` 客户端程序信息等请求相关的字段
3. 响应首部字段，响应时相关字段
4. 实体首部字段，主要是 Content 相关字段，主要规定实体特征。实体首部字段在请求和响应中都可能有，只和请求体相关；如果请求没有请求体（GET/HEAD），则不会携带该字段

HTTP 头会按照`请求/响应 - 通用 - 实体`顺序分别安排四种首部

全部字段见：
https://juejin.cn/post/6844903748196646920

每个字段的用处，可以参考《图解 HTTP》

#### 常见的请求头

- `Accept`:浏览器能够处理的内容类型，即 MIME type
- `Accept-Charset`:浏览器能够显示的字符集，优先选择该字符集发送
- `Accept-Encoding`：浏览器能够处理的压缩编码
  - gzip: 当今最流行的压缩格式
  - deflate: 另外一种著名的压缩格式
  - br: 一种专门为 HTTP 发明的压缩算法
- `Accept-Language`：浏览器当前设置的语言

Accept 字段通常表示一种“优先选择”，即浏览器希望服务器发送一个希望的类型，并不是直接对发送的指示和标识。

- `Authorization`: Web 认证信息，通常用于携带 jwt、token 等认证信息。
- `Connection`：浏览器与服务器之间连接的类型
- `Cookie`：当前页面设置的任何 Cookie
- `Host`：发出请求的页面所在的域
- `Referer`：发出请求的页面的 URL
- `User-Agent`：浏览器的用户代理字符串
- `X-Forwarded-For`：用于保存最开始发起请求的客户端的 IP 地址。主要为了解决因为多个代理服务器导致的服务端无法获取到原始的客户端的ip地址的问题。值：

```
按顺序表示客户端ip、代理服务器1ip、代理服务器2ip等
X-Forwarded-For: 203.0.113.195, 70.41.3.18, 150.172.238.178
```

####  常见的响应头

- `Date`：表示消息发送的时间，时间的描述格式由 rfc822 定义
- `Server`:服务器名称
- `Connection`：浏览器与服务器之间连接的类型
- `Cache-Control`：控制 HTTP 缓存

#### 常见的实体首部

- `Content-Encoding` 实体主体适用的编码方式
- `Content-Language` 实体主体的自然语言
- `Content-Length` 实体主体的大小。一般用于设置定长包体的长度，实际请求体大于长度将会被截取，小于则会报错；
- `Content-Location` 替代对应资源的 URI
- `Content-MD5`实体主体的报文摘要
- `Content-Range` 实体主体的位置范围
- `Content-Type` 实体主体的媒体类型
- `Expires` 实体主体过期的日期时间
- `Last-Modified` 资源的最后修改日期时间

常见的 `Content-Type` 属性值有：

1. `application/x-www-form-urlencoded`：浏览器的原生 `form` 表单，如果不设置 `enctype` 属性，那么最终就会以 `application/x-www-form-urlencoded `方式提交数据。该种方式提交的数据放在 body 里面，数据按照 `key1=val1&key2=val2` 的方式进行编码，key 和 val 都进行了 URL 转码。
2. `multipart/form-data`：该种方式也是一个常见的 POST 提交方式，通常表单上传文件时使用该种方式。
3. `application/json`：服务器消息主体是序列化后的 JSON 字符串。
4. `text/xml、text/plain`：该种方式主要用来提交 XML 格式、纯文本格式的数据。

### HTTP 请求方法

- `GET` **请求**指定的页面信息，并返回实体主体。
- `HEAD` 类似于 get 请求，只不过返回的响应中没有具体的内容，用于获取**报头**
- `POST` 向指定资源**提交**数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST 请求可能会导致新的资源的建立和/或已有资源的修改。
- `PUT` 从客户端向服务器传送的数据**取代**指定的文档的内容。
- `DELETE` **删除**
- `CONNECT` **连接**，比如 websocket 的最开始的请求方法就是 connect
- `OPTIONS` 用于**检测**服务器允许的 http 方法，一般是浏览器进行预检的时候自动发送的，跨域之前非简单请求就需要先发 options 获知服务端是否允许跨域
- `TRACE` 回显服务器收到的请求，主要用于**测试**或诊断。

方法分类:

- `Safe`:一定不会修改服务器上资源的请求，get、head、options
- `Idempotent`：幂等，除安全以外的请求，**一个请求被执行一次和执行多次服务器状态一样，效果一样**

### HTTP 状态码

- 1xx：指示信息--表示请求已接收，继续处理
  - 100：继续 服务器返回此代码表示已收到请求的第一部分，正在等待其余部分。
  - 101：切换协议 请求者已要求服务器切换协议，服务器已确认并准备切换.HTTP 升级为 WebSocket 的时候，如果服务器同意变更，就会发送状态码 101。
- 2xx：成功--表示请求已被成功接收、理解、接受
  - 204：成功但没有 body
- 3xx：重定向--要完成请求必须进行更进一步的操作；
  - 301：所请求的页面已经永久重定向至新的 URL
  - 302：所请求的页面已经临时重定向至新的 URL
  - 303：查看其它位置 表示对应当前请求的响应可以在另一个 URI 上被找到，而且客户端应当采用 GET 的方式访问那个资源。
  - 304：缓存相关，表示资源未更改可以使用缓存
  - 305：必须通过指定的代理才能访问
- 4xx：客户端错误--请求有语法错误或请求无法实现
  - 400：Bad Request 请求错误，通常是域名未解析到正确的 IP，或解析后，服务器端未绑定此域名导致。
  - 401：未授权 请求要求身份验证。对于需要登录的网页，服务器可能返回此响应
  - 403：禁止 服务器拒绝请求
  - 404：未找到 服务器找不到请求的资源
  - 405：方法禁用 禁用请求中指定的方法
  - 406 Not Acceptable: 资源无法满足客户端的条件。
  - 408 Request Timeout: 服务器等待了太长时间。
  - 409 Conflict: 多个请求发生了冲突。
  - 413 Request Entity Too Large: 请求体的数据过大。
  - 414 Request-URI Too Long: 请求行里的 URI 太大。
  - 429 Too Many Request: 客户端发送的请求过多。
  - 431 Request Header Fields Too Large 请求头的字段内容太大。
- 5xx：服务器端错误--服务器未能实现合法的请求
  - 500：服务器内部错误 服务器遇到错误，无法完成请求
  - 501：尚未实施 服务器不具备完成请求的功能。例如，服务器无法识别请求方法时可能会返回此代码
  - 502：错误网关 通常是服务器脚本语言端未启动或无响应，以及反向代理端无响应。一般表现为你自己写的应用层服务(Java/Go/PHP)挂了，网关层无法接收到响应。502通常是已经和后端建立连接，但是请求无响应
  - 503：服务器不可用 服务器目前无法使用（由于超载或者停机维护）。通常，这只是暂时状态
  - 504：网关超时。504常出现于响应时间超过nginx代理服务器配置的超时时间，可能是后端代码出现死循环、sql语句查询太慢等情况。
  - 505：HTTP 版本不受支持 服务器不支持请求中所用的 HTTP 协议版本


### HTTPS

![](https://pic.imgdb.cn/item/623400465baa1a80abe10fb0.jpg)

- HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 `TCP` 和 `HTTP` 应用层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。实际上 ssl 在应用层和传输层之间，更偏向属于应用层。
- HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。
- HTTPS 的端口号是 443。
- HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

![https.jpg](https://i.loli.net/2021/12/02/Wlm3TKsZYBtc67H.png)

#### https 的安全依据

https://segmentfault.com/a/1190000021494676

1. 对称和非对称混合加密（对称：加密和解密用的同一套密钥，非对称就是不同套密钥）

> 对称加密，顾名思义就是加密和解密都是使用同一个密钥，常见的对称加密算法有 DES、3DES 和 AES 等，其优缺点如下：
> 优点：算法公开、计算量小、加密速度快、加密效率高，适合加密比较大的数据。
> 缺点：
> 交易双方需要使用相同的密钥，也就无法避免密钥的传输，而密钥在传输过程中无法保证不被截获，因此对称加密的安全性得不到保证。每对用户每次使用对称加密算法时，都需要使用其他人不知道的惟一密钥，这会使得发收信双方所拥有的钥匙数量急剧增长，密钥管理成为双方的负担。对称加密算法在分布式网络系统上使用较为困难，主要是因为密钥管理困难，使用成本较高。

> 非对称加密，顾名思义，就是加密和解密需要使用两个不同的密钥：公钥（public key）和私钥（private key）。公钥与私钥是一对，如果用公钥对数据进行加密，只有用对应的私钥才能解密；如果用私钥对数据进行加密，那么只有用对应的公钥才能解密。非对称加密算法实现机密信息交换的基本过程是：甲方生成一对密钥并将其中的一把作为公钥对外公开；得到该公钥的乙方使用公钥对机密信息进行加密后再发送给甲方；甲方再用自己保存的私钥对加密后的信息进行解密。
> ![](https://pic.imgdb.cn/item/623413cf5baa1a80abeee528.png)

2. 摘要算法，简单来说就是客户端发送明文数据之前会通过摘要算法算出明文的“指纹”，然后服务器需要进行比较客户端携带的和自己存储的，如果一致就是安全的
3. 数字证书

- 客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密
- 借助第三方权威机构 CA （数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。

#### 基本流程

这个握手过程实际上是HTTPS的RSA握手过程，一共要进行四次握手

概述：
![](https://pic.imgdb.cn/item/623415d65baa1a80abf041be.jpg)

具体参数传递：
![](https://pic.imgdb.cn/item/627b9fda0947543129f65d89.jpg)

1. 客户端请求 HTTPS 网址，然后连接到 server 的 443 端口 (HTTPS 默认端口，类似于 HTTP 的 80 端口)。客户端发送请求时会带上自己的一个随机码`client_random`以及 TLS 版本，还有一个加密套件列表。

> 加密套件是指加密的方法，加密套件列表就是指浏览器能支持多少种加密方法列表。

2. 采用 HTTPS 协议的服务器必须要有一套数字 CA (Certification Authority)证书，证书是需要申请的，并由专门的数字证书认证机构(CA)通过非常严格的审核之后颁发的电子证书。颁发证书的同时会产生一个`私钥`和`公钥`。`私钥`由服务端自己保存，不可泄漏。`公钥`则是附带在证书的信息中，可以公开的。证书本身也附带一个证书电子签名，这个签名用来验证证书的完整性和真实性，可以防止证书被篡改。

3. 服务器响应客户端请求；从客户端提供的加密套件列表中选一个加密套件并发送，将证书传递给客户端，同时还会发送一个客户端生成的随机码`server_random`和`server_params`

4. 客户端解析证书并对其进行验证。如果证书没有问题，客户端就会从服务器证书中取出服务器的`公钥`。然后客户端还会再生成一个随机码`client_params`，将其用公钥加密后传输给服务端；然后用之前的`server_params`和自己的`client_params`一起生成一个`pre_random`（也叫`pre_master`），将这三个数通过一个伪随机数函数来计算出最终的 secret。

5. 服务器在收到随机码 `client_params` 之后会使用`私钥`将其解密。这时服务端已经拥有了`client_params`和自己生成的`server_params`，服务端也类似的生成`pre_random`，接着用和客户端同样的伪随机数函数生成最后的 secret。

7. 双方使用 secret 传输所有数据。

> 客户端只拥有公钥，服务端还额外拥有一个私钥，用于解密客户端用公钥加密后的数据。

上述算法是HTTPS的RSA算法，是之前的一个版本，现在被ECDHE所代替，主要原因是RSA的缺点，即不支持**前向保密**，也就是说一旦服务器的私钥泄露，那么之前的所有信息都会被暴露

#### SSL/TLS

SSL 和 TLS 协议可以为通信双方提供识别和认证通道，从而保证通信的机密性和数据完整性。TLS 协议是从 SSL 协议演变而来的，不过这两种协议并不兼容，SSL 已经逐渐被 TLS 取代，所以下文就以 TLS 指代安全层。
TLS 握手是启动 HTTPS 通信的过程，类似于 TCP 建立连接时的三次握手。 在 TLS 握手的过程中，通信双方交换消息以相互验证，相互确认，并确立它们所要使用的加密算法以及会话密钥 (用于对称加密的密钥)。可以说，TLS 握手是 HTTPS 通信的基础部分。

TLS 握手的主要过程其实就是 HTTPS 建立连接的基本流程，主要工作有：

- 商定双方通信所使用的的 TLS 版本 (例如 TLS1.0, 1.2, 1.3 等等)；
- 确定双方所要使用的密码组合；
- 客户端通过服务器的公钥和数字证书 (上篇文章已有介绍)上的数字签名验证服务端的身份；
- 生成会话密钥，该密钥将用于握手结束后的对称加密。

### HTTP版本

#### HTTP0.9

HTTP/0.9 是于 1991 年提出的，主要用于学术交流，需求很简单——用来在网络之间传递 HTML 超文本的内容。

HTTP/0.9 的实现有以下三个特点：

- 第一个是只有一个请求行，并没有HTTP 请求头和请求体，因为只需要一个请求行就可以完整表达客户端的需求了。也就是说它只能发送最简单的GET请求，而且只能请求到对应的HTML文档的字节流形式。
- 第二个是服务器也没有返回头信息，这是因为服务器端并不需要告诉客户端太多信息，只需要返回数据就可以了。
- 第三个是返回的文件内容是以 ASCII 字符流来传输的，因为都是 HTML 格式的文件，所以使用 ASCII 字节码来传输是最合适的。

#### HTTP1.0

相对于HTTP0.9，1.0增加了一些功能，包括：

- 请求头和响应头
- 除字节流之外的其他类型数据的传输
- 状态码
- 基本的缓存功能，比如`If-Modified-Since`、`Expires`等缓存头；这些在http1.1中得到更新替换

HTTP 1.0 规定浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个 TCP 连接，服务器完成请求处理后立即断开 TCP 连接，服务器不跟踪每个客户也不记录过去的请求，类似于之前说过的非持续连接的 HTTP 请求。

http1.0 最大的两个问题是

- 连接无法复用，会导致每次请求都经历三次握手和慢启动，即使带宽很大、文件很小，依然要耗费不少时间；
- head of line blocking（队头阻塞）：致带宽无法被充分利用，以及后续健康请求被阻塞。

> 队头阻塞：
> 请求在客户端会形成队列，由于每次只能发送一个报文，并且在接受响应之前不会再次发送，因此队列里排在最前面的请求会被最优先处理。如果队首的请求因为处理的太慢耽误了时间，那么队列里后面的所有请求也不得不跟着一起等待，结果就是其他的请求承担了不应有的时间成本，造成了队头堵塞的现象。

#### HTTP1.1

HTTP 1.1 支持持久连接，在一个 TCP 连接上可以传送多个 HTTP 请求和响应，减少了建立和关闭连接的消耗和延迟。HTTP1.1 请求头中的`Connection`就是规定如何长连接的。
HTTP 1.1 通过增加更多的请求头和响应头来改进和扩充 HTTP 1.0 的功能。

HTTP1.1 和 HTTP1.0 主要区别有：

- **长连接**，http1.0 默认使用非持久连接，而 http1.1 默认使用持久连接。长连接依然是一收一发的形式，并没有修复原有的队头阻塞问题
- **并发连接**：又被称为流水线，允许客户端和服务端建多个并发连接（Chrome 中是 6 个），减少队头阻塞。并发连接是建立多个TCP连接，在每个连接上执行一个HTTP的收发过程，和 http2 的多路复用不一样。
  ![image-20220610103955930](https://blog-img-1307852525.cos.ap-chengdu.myqcloud.com/img/image-20220610103955930.png)
- **支持请求部分资源和断点续传**，在 http1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，http1.1 则在请求头引入了 Range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。

- **缓存控制头增加**，在 http1.0 中主要使用 header 里的 `If-Modified-Since`、`Expires` 来做为缓存判断的标准，http1.1 则引入了更多的缓存控制策略，例如`Etag`、`If-Unmodified-Since`、`If-Match`、`If-None-Match` 等更多可供选择的缓存头来控制缓存策略。
- **HOST 字段的添加**：http1.1 中新增了 host 字段，用来指定服务器的域名。http1.0 中认为每台服务器都绑定一个唯一的 IP 地址，因此，请求消息中的 URL 并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机，并且它们共享一个 IP 地址。因此有了 host 字段，这样就可以将请求发往到同一台服务器上的不同网站。
- **新增几个请求方法**：http1.1 相对于 http1.0 还新增了很多请求方法，如 PUT、HEAD、OPTIONS 等。

#### HTTP2.0

http1.1的一个核心问题是其对带宽的利用率太低。主要原因是频繁触发TCP的慢启动而慢启动过程对带宽利用率太低，并且队头阻塞问题并没有从根本上获得解决。

![](https://pic.imgdb.cn/item/627ba1480947543129fa0dc1.jpg)

HTTP2.0 相对于 HTTP1.1 的变化：

- **永久连接**，没有 1.1 中的 keep-alive。在整个传输过程中，始终有且只有一个TCP连接，在一个TCP连接上完成所有的请求响应过程，而不需要建立多个TCP连接。
- **二进制协议**：HTTP/2 采用二进制格式传输数据，而非 HTTP 1.x 的文本格式；二进制是整个报文都是二进制，包括头部和实体，统称为"帧"
- **多路复用**：在一个连接里，客户端和服务器都可以同时发送多个请求或回应，而且不用按照顺序一一发送
- **优先级机制**：每个请求都可以带一个优先值，0 表示最高优先级， 数值越大优先级越低，这样可以自行选择处理帧的方式。优先级和多路复用都解决了 HTTP 的老问题“`队头阻塞`”
- **服务器推送 Server Push**：服务器可以主动向用户**推送** js、css，而不是只能拿通过解析 html 获得
  > server push 和 websocket 的区别：
  > - HTTP2 Server Push，一般用以服务器根据解析 index.html 同时推送 图片/JS/CSS 等资源，而免了服务器发送多次请求
  > - websocket，用以服务器与客户端手动编写代码去推送进行数据通信
- **头部压缩**：
  - 头信息使用 gzip 或 compress 压缩后再发送
  - 客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号。

---

HTTP/2 的多路复用是为了解决HTTP1.1的性能问题。
在 HTTP/2 中，有两个非常重要的概念，分别是帧（frame）和流（stream）。

- 帧代表着最小的数据单位。帧包含一个用于标识的ID，客户端和服务端都会根据ID将不同的帧合并成一个完整的请求
- 通信双方都可以给对方发送二进制帧，这种二进制帧的**双向传输的序列**，也叫做流(Stream)。同域名下所有通信都在单个连接上完成，该连接可以承载任意数量的双向数据流。每个数据流都以消息的形式发送，而消息又由一个或多个帧组成。多个帧之间可以乱序发送，根据帧首部的流标识可以重新组装。

多路复用，就是**在一个 TCP 连接中可以存在多条流**。换句话说，也就是**可以发送多个请求**，对端可以通过**帧中的标识知道属于哪个请求**。通过这个技术，可以避免 HTTP 旧版本中的队头阻塞问题，极大的提高传输性能。

通过多路复用，HTTP2的请求和接收过程改变为如下：

1. 首先，浏览器准备好请求数据，包括了请求行、请求头等信息
2. 这些数据经过二进制分帧层处理之后，会被转换为一个个带有请求 ID 编号的帧，通过协议栈将这些帧发送给服务器。
3. 服务器接收到所有帧之后，会将所有相同 ID 的帧合并为一条完整的请求信息。
4. 然后服务器处理该条请求，并将处理的响应行、响应头和响应体分别发送至二进制分帧层。
5. 同样，二进制分帧层会将这些响应数据转换为一个个带有请求 ID 编号的帧，经过协议栈发送给浏览器。

浏览器接收到响应帧之后，会根据 ID 编号将帧的数据提交给对应的请求

> 二进制帧
> ![](https://pic.imgdb.cn/item/627ba15b0947543129fa3ad7.jpg)
> 每个帧分为帧头和帧体。先是三个字节的帧长度，这个长度表示的是帧体的长度。
> 然后是帧类型，大概可以分为数据帧和控制帧两种。数据帧用来存放 HTTP 报文，控制帧用来管理流的传输。

#### HTTP 3.0

参考：https://hungryturbo.com/HTTP3-explained/quic/%E5%8D%8F%E8%AE%AE%E7%89%B9%E7%82%B9.html

HTTP3.0的改变主要体现在它不再基于tcp，而是采用udp作为传输层协议。具体来说是基于udp的QUIC协议。

![](https://pic.imgdb.cn/item/63eb5322f144a0100775627e.jpg)

虽然HTTP2解决了http层面的队头阻塞问题，但并没有解决TCP层面的。使用HTTP/2的双方如果有一个数据包在网络中丢失，或者网络中断都会造成整个TCP连接的暂停，丢失的数据包将被重新传输到目的地。由于TCP是一个链条，因此如果其中一个连接突然丢失，那么该连接之后的连接就都需要等待。
由于HTTP2只使用一个TCP连接，因此如果连接出现丢包、中断等问题，影响会比HTTP1.1还要大很多。

QUIC可以看做是在UDP的基础上建立了一些功能，包括：
1. 建立连接：UDP是无连接的协议，QUIC在通信之前需要先建立连接。QUIC建立连接时，加密算法的版本协商与传输层握手合并完成，以减小延迟。

每个连接过程都有一组连接标识符，或称连接ID，该ID用以识别该连接。每个端点各自选择连接ID。每个端点选择其对等方使用的连接ID。这些连接ID的主要功能是确保较低协议层（UDP、IP及其底层协议）的地址更改不会导致QUIC连接的数据包传递到错误的端点。
通常利用连接ID，可以在IP地址和网络接口迁移的情况下得到保持，比如一个连接可以在wifi良好时使用wifi连接，在wifi断开时使用移动网络连接，这其中虽然IP改变，但连接可以不用重新建立。

2. 数据流：类似HTTP2中的流的概念。UIC中有两种基本的数据流类型：

- 从发起者到对等端（Peer）的单向数据流。
- 双向均可发出数据的双向数据流。

连接端点的任意一方都可以建立这两种数据流，数据流之间可并行、交错地传输，并且可以被取消。为了通过QUIC发送数据需要建立一个或多个数据流。
数据流是QUIC传递数据的关键，多个流相互独立，多个流之间是乱序交付的。每个流内部实现了一些基本功能，比如重传机制、丢包超时处理等。流和流之间的交付不一定有序，但同一个流内部一定是有序的。

3. 0-RTT：为了减少建立新连接所需的时间，先前已连接到服务器的客户端可以**缓存来自该连接的某些参数**，然后与服务器建立0-RTT连接。从而客户端可以立即发送数据，而无需等待握手完成。

4. 服务器推送：类似HTTP2，但机制不同，客户端可以限制服务器推送的数量和次数

### HTTP 代理

代理实际上是一个服务器，假设在服务器和客户端之间，作为一个中间人的身份；请求并不是直接发送给服务器，而是先经过代理服务器进行一些操作，然后再发给服务器；响应也是同理。
代理服务器主要功能有：

- **负载均衡**。代理服务器可以拿到这个请求之后，可以通过特定的算法分发给不同的源服务器，让各台源服务器的负载尽量平均。
- **保障安全**。利用心跳机制监控后台的服务器，一旦发现故障机就将其踢出集群。并且对于上下行的数据进行过滤，对非法 IP 限流，这些都是代理服务器的工作。
- **缓存代理**。将内容缓存到代理服务器，使得客户端可以直接从代理服务器获得，也叫做 Web 缓存；从计算机网络的角度，这样的代理通常设置在区域 ISP 中。实际上 HTTP 缓存的实现就是依赖代理服务器，或者叫做缓存器。


#### 代理字段

- `Via`：记录代理服务器。每经过一个代理服务器就向这个字段添加当前代理的身份，添加的顺序就是经过代理服务器的顺序。

```
Via: proxy_server1, proxy_server2
```

- `X-Forwarded-For`：字面意思就是为谁转发, 它记录的是请求方的 IP 地址
- `X-Real-IP`：是一种获取用户真实 IP 的字段，不管中间经过多少代理，这个字段始终记录最初的客户端的 IP
- `Cache-Control`中的`s-maxage`字段：限定了缓存在代理服务器中可以存放多久，即相当于代理服务器中的`max-age`。

#### 代理缓存

对于 HTTP 缓存来说，如果每次客户端缓存失效都要到源服务器获取，那给源服务器的压力是很大的。
由此引入了缓存代理的机制。让代理服务器接管一部分的服务端 HTTP 缓存，客户端缓存过期后就近到代理缓存中获取，代理缓存过期了才请求源服务器，这样流量巨大的时候能明显降低源服务器的压力。
缓存代理的控制分为两部分，一部分是源服务器端的控制，一部分是客户端的控制。

1. **源服务器控制**：主要通过`Cache-Contro`字段控制。

- `private`或者`public`表示是否允许代理服务器缓存，前者禁止，后者为允许。
- `must-revalidate`的意思是客户端缓存过期就去源服务器获取，而`proxy-revalidate`则表示代理服务器的缓存过期后到源服务器获取。
- `s-maxage`:限定了缓存在代理服务器中可以存放多久，即相当于代理服务器中的`max-age`。

2. **客户端控制**：通过向请求头中添加几个字段：

- `max-stale` 和 `min-fresh`：`max-stale`表示客户端到代理服务器上拿缓存的时候，即使代理缓存过期了也不要紧，只要过期时间在多长时间之内，还是可以从代理中获取的。`min-fresh`正相反，要求至少提前多长时间。

### HTTP 缓存

#### 缓存的分类

缓存根据位置和使用的对象可以分成两类：

- web 缓存、代理缓存、共用缓存：以被多个用户使用，一般是架设在 ISP 的代理服务器，作为用户主机和外部的中介
- 浏览器缓存：即通过请求和响应头设置的缓存，一般存储在用户主机本地，只能服务于单独用户，并且常见的 http 缓存只能缓存 get 请求响应的资源；
  浏览器缓存可以根据缓存存放的**位置**分为 3 类
  - `Service Worker`：<a href="https://developer.mozilla.org/zh-CN/docs/Web/API/Service_Worker_API/Using_Service_Workers">MDN-Service Worker</a>具体介绍了这个 api。它可以被理解为是一个介于浏览器和网络请求之间的拦截器，像webworker一样运行在主线程之外，其中的一个主要功能就是控制缓存的存储和读取，可以完成**离线缓存**、消息推送、网络代理等功能；若没有在 Service Worker 命中缓存，会根据缓存查找优先级去查找数据。
  - `Memory Cache`：内存缓存，效率最高最快，但一旦关闭 Tab 页面就不再保存。通常情况下打开一个页面的缓存会首先保存在Memory Cache中，如果通过F5刷新页面，就会从内存中直接获取缓存；关闭页面后消失，但会保留一份副本在Disk Cache中
  - `Disk Cache`：存储在硬盘中的缓存，覆盖面基本是最大的，会根据 HTTP Herder 中的字段判断哪些资源需要缓存，哪些资源可以不请求直接使用，哪些资源已经过期需要重新请求。关闭页面后将从这里获取，但不一定是全部读取，还要根据缓存策略、字段等信息判断是否需要缓存还是重新请求。
  - `Push Cache`：HTTP/2 的缓存，以上三种都没有才会使用，并且生命周期和 session 一致

上面的四个缓存，针对用户行为的不同有不同的访问优先级：
- 用户直接输入url或通过历史记录访问：检查disk cache中的缓存是否存在、是否符合强缓存要求；否则则发送请求
- 用户F5刷新：优先使用Memory Cache，没有再取Disk Cache
- 用户Ctrl+F5刷新：不选择缓存，直接重新请求

#### http 缓存

> HTTP 缓存主要是通过请求和响应报文头中的对应 Header 信息，来控制缓存的策略。响应头中相关字段为 `Expires`、`Cache-Control`、`Last-Modified`、`Etag`。
> 缓存两种类型: **强缓存** / **协商缓存**
> 从物理上，http 缓存依靠代理服务器（又叫 Web 缓存器）存储缓存信息；Web 缓存器相当于一个中转站：
>
> - 当客户端请求时，**将请求定向至缓存器**，会先经过缓存器并检查是否存有副本，如果有会直接返回；如果没有则会向服务器发送请求
> - 服务器响应请求给缓存器，缓存器将文件在本地保存，返回给客户端；当下一次客户端请求时会给予之前的副本而不是直接请求服务器

缓存类型有两种：

- 强缓存: 如果缓存在缓存器缓存数据库中存在,就强制使用缓存而不是请求服务器; 如果没有缓存就请求服务器并取得缓存,下次使用缓存
  ![](https://pic.imgdb.cn/item/623439926eeb7459a2832d75.jpg)
- 协商缓存/对比缓存: 无论有无缓存都会向服务器请求, 比较判断是否可以使用缓存。浏览器再次请求数据时，浏览器将备份的缓存标识发送给服务器，服务器根据缓存标识进行判断，判断成功后，返回 304 状态码，通知客户端比较成功，可以使用缓存数据。第二次的请求大小会比第一次小很多, 一般不包含静态资源缓存, 因此要快很多
  ![](https://pic.imgdb.cn/item/623439f15baa1a80ab0c3519.jpg)

> 不存在缓存数据或者未过期时会采用强缓存，获取之后在进行缓存；  
> 如果缓存过期，会采用协商缓存检查本地缓存是否还有效  
> 允许使用浏览器本地缓存的状态码是`304`，表示资源未改变，可以使用缓存
> 判断流程：![](https://pic.imgdb.cn/item/62343dc85baa1a80ab0e7589.jpg)
>
> 这张图从浏览器角度看更清晰：![](https://pic.imgdb.cn/item/6237f03627f86abb2af51f05.jpg)

#### 强缓存

在没有缓存数据的时候，浏览器向服务器请求数据时，服务器会将数据和缓存规则一并返回，缓存规则信息包含在响应 header 中。
在缓存数据未失效的情况下，浏览器会直接使用缓存数据；浏览器判断数据失效的依据是响应头部的缓存相关字段；如果失效，则会再次向服务器请求。

缓存相关字段如下：

- `Expires`：服务端返回的到期时间，即下一次请求时，请求时间小于服务端返回的到期时间，直接使用缓存数据。在 HTTP 1.1 的版本，Expires 被 Cache-Control 替代。
- `Cache-Control`：常见的取值有 private、public、no-cache、max-age，no-store，默认为 private。
  - `max-age=xxx`：用来设置资源（representations）可以被缓存多长时间，单位为秒；
  - `public`：指示响应可被任何缓存区缓存；
  - `private`：只能针对个人用户，而不能被代理服务器缓存；对前端来说这两个没什么太多区别
  - `no-cache`：强制客户端直接向服务器发送请求,也就是说每次请求都必须向服务器发送。服务器接收到请求，然后判断资源是否变更，是则返回新内容，否则返回 304，未变更。
  - `no-store`：禁止一切缓存（这个才是响应不被缓存的意思）。
  - `must-revalidate`：类似no-cache，强制重新请求
  - `s-maxage`：限定了缓存在代理服务器中可以存放多久，和限制客户端缓存时间的 max-age 并不冲突。`s-maxage`出现时将无视 expires 字段。

#### 协商缓存

浏览器第一次请求数据时，服务器会将缓存标识与数据一起返回给客户端，客户端将二者备份至缓存数据库中。
再次请求数据时，客户端将备份的缓存标识发送给服务器，服务器根据缓存标识进行判断，判断成功后，返回 304 状态码，通知客户端比较成功，可以使用缓存数据。

> 协商缓存的判断字段分为两组，第一组依据修改时间判断是否过期、是否需要重传；第二组通过唯一标识符判断；  
> 两组内部的值其实相同，只是组内的前者是响应头内的，后者是请求头内的。  
> **第二组**的优先级高一些；

- `Last-Modified` ：最后修改时间
- `If-Modified-Since`：再次请求服务器时，通过此字段通知服务器上次请求时，服务器返回的资源最后修改时间。

服务器收到请求后发现有头`If-Modified-Since` 则与被请求资源的最后修改时间进行比对。

- 若资源的最后修改时间大于`If-Modified-Since`，说明资源又被改动过，则响应整片资源内容，返回状态码 200；
- 若资源的最后修改时间小于或等于`If-Modified-Since`，说明资源无新修改，则响应 HTTP 304，告知浏览器继续使用所保存的 cache。

> `Last-Modified`判断的形式是有一点问题的，因为它是以秒计时的。如果在较短事件完成修改，可能会导致即使修改了但该值并没有改变。并且如果只是打开但没有修改也会更新该值。为了解决问题，更好的方式就是Etag。

---

- `Etag`：服务器对资源的唯一标识
- `If-None-Match`：再次请求服务器时，通过此字段通知服务器客户段缓存数据的唯一标识。

服务器收到请求后发现有头`If-None-Match` 则与被请求资源的唯一标识（Etag）进行比对，

- 不同，说明资源又被改动过，则响应整片资源内容，返回状态码 200；
- 相同，说明资源无新修改，则响应 HTTP 304，告知浏览器继续使用所保存的 cache。

#### 条件 GET

浏览器通过条件 GET（也就是报文中首部行的`If-Modified-Since`）**判断缓存器上的副本是否是最新的**，具体步骤如下：

1. 代理缓存器第一次向服务器发送请求，服务器返回的报文首部行中有一个`Last-Modified`字段被一并保存；
2. 一段时间后当客户端请求时，代理缓存器会发送一个 GET 请求，其中首部行带有`If-Modified-Since`字段，并且值就是之前的`Last-Modified`字段，表示上次请求的时间

```
GET / HTTP/1.1
HOST: www.xxx.com
If-Modified-Since: Wed, 9 Sep 2020 09:23:24
```

3. 服务器对条件 GET 做出响应：

- 状态码 304，说明可以继续使用缓存
- 其他情况，发送新的响应体，重新缓存

4. 将缓存响应给客户端

### HTTP 其他功能

#### 大文件传输（分段传输）

HTTP 针对这一场景，采取了范围请求的解决方案，允许客户端仅仅请求一个资源的一部分。

要支持这个功能，就必须加上这样一个响应头:

```
Accept-Ranges: bytes
```

而对于客户端而言，它需要指定请求哪一部分，通过 Range 这个请求头字段确定，格式为 bytes=x-y。
比如：

```
// 单段数据
Range: bytes=0-9
// 多段数据
Range: bytes=0-9, 30-39
```

> Range 的书写格式:
> 0-499 表示从开始到第 499 个字节。
> 500- 表示从第 500 字节到文件终点。
> -100 表示文件的最后 100 个字节。
> 服务器收到请求之后，首先验证范围是否合法，如果越界了那么返回`416`错误码;否则读取相应片段，返回`206`状态码。

响应对于单端数据的处理和多段数据不同。

1. 单段数据：核心是`Content-Range`字段，表示响应的返回部分和总资源的大小。

```
HTTP/1.1 206 Partial Content
Content-Length: 10
Accept-Ranges: bytes
Content-Range: bytes 0-9/100

i am xxxxx
```

2. 多段数据：
1. `Content-Type: multipart/byteranges; boundary=00000010101`这个字段表示响应体是一个多段数据，用 boundary 值为 00000010101 来分割。
1. 每一段都会先用 boundary 分割，然后展示本段的类型（`Content-Type`）和范围（`Content-Range`），再在一个空行之后放入正常的响应体即可。
1. 在最后的分隔末尾添上--表示结束。

```
HTTP/1.1 206 Partial Content
Content-Type: multipart/byteranges; boundary=00000010101
Content-Length: 189
Connection: keep-alive


--00000010101
Content-Type: text/plain
Content-Range: bytes 0-9/96

i am xxxxx
--00000010101
Content-Type: text/plain
Content-Range: bytes 20-29/96

eex jspy e
--00000010101--
```

## DNS

DNS 是域名系统 (Domain Name System) 的缩写，提供的是一种主机名到 IP 地址的转换服务，就是我们常说的域名系统。它是一个由分层的 DNS 服务器组成的分布式数据库，是定义了主机如何查询这个分布式数据库的方式的应用层协议。能够使人更方便的访问互联网，而不用去记住能够被机器直接读取的 IP 数串。

在定义上，DNS 既是一个由分层的 DNS 服务器实现的 DNS**数据库**，又是一个提供这项功能的应用层**协议**。

作用：将域名解析为 IP 地址，客户端向 DNS 服务器（DNS 服务器有自己的 IP 地址）发送域名查询请求，DNS 服务器告知客户机 Web 服务器的 IP 地址。

> DNS 用作域名解析时运行在 UDP 上，53 号端口
> DNS 在区域传输时使用 TCP，即根服务器、权威服务器等之间的数据交换

### 查询过程

DNS 采用分布式层次数据库的方式，使 IP 地址--域名的映射分布在所有 DNS 服务器上。这些服务器大致分为三类：

- 根 DNS 服务器：提供顶级域（TLD）服务器的 IP 地址
- TLD DNS 服务器：顶级域即类似`.com`、`.cn`这样的域名中的顶级域，这些顶级域提供权威 DNS 服务器的 IP
- 权威 DNS 服务器：真正存储映射的地方，维护一个区域的映射。
- 本地 DNS 服务器：虽然不属于分布式的一部分，但是和用户直接相连，用于向其他服务器发送；同时也带有 DHCP 服务器，供用户获取自己的 IP 地址。

DNS 服务器解析域名的过程：

1. 首先会在**浏览器的缓存**中查找对应的 IP 地址，如果查找到直接返回，若找不到继续下一步
1. 将请求发送给本地 DNS 服务器，在**本地 DNS 服务器缓存**中查询，如果查找到，就直接将查找结果返回，若找不到继续下一步
1. 本地 DNS 服务器向**根域名服务器**发送请求，根域名服务器会返回一个所查询域的顶级域名服务器地址
1. 本地 DNS 服务器向**顶级域名服务器**发送请求，接受请求的服务器查询自己的缓存，如果有记录，就返回查询结果，如果没有就返回相关的下一级的权威域名服务器的地址
1. 本地 DNS 服务器向**权威域名服务器**发送请求，域名服务器返回对应的结果
1. 本地 DNS 服务器将返回结果保存在缓存中，便于下次使用
1. 本地 DNS 服务器将返回结果返回给浏览器

上面这种方式，本地 DNS 分别向三个层次发送请求，这种方式是`迭代查询`。
如果是`本地DNS->根DNS->TLD DNS->权威DNS->原路返回`这样的形式，就是`递归查询`。

## CDN

CDN（内容分发网络）：尽可能避开互联网上有可能影响数据传输速度和稳定性的瓶颈和环节，使内容传输的更快、更稳定。通过在网络各处放置节点服务器所构成的在现有的互联网基础之上的一层智能虚拟网络，CDN 系统能够实时地根据网络流量和各节点的连接、负载状况以及到用户的距离和响应时间等综合信息将用户的请求重新导向离用户最近的服务节点上。
也就是说，cdn 可以尽可能把你连接到最近、最快的服务器

cdn 由一个 dns 服务器和几台缓存服务器组成，dns 服务器用作接入并返回合适的缓存服务器；缓存服务器存储真正的内容，会被分配到不同的用户。

1. 当用户点击网站页面上的内容 URL，经过本地 DNS 系统解析，并不会直接返回对应的 IP 地址，而是返回一个 CDN 服务器的域名（注意是域名不是 ip）
2. 用户向返回的这个 CDN 服务器域名发起请求。
3. CDN 服务器根据用户 IP 地址，以及用户请求的内容 URL，选择一台用户所属区域的区域负载均衡设备，返回给这台设备的 IP 地址
4. 用户通过本地 dns 向该 ip 发起连接。



# 传输层

传输层建立在网络层之上和应用层之下，为运行在不同主机上的不同进程之间提供了逻辑通信。
传输层的主要功能：

1. 多路复用和多路分解：由于网络层只负责主机到主机的传输，具体到进程需要传输层控制。把进程和运输层之间不同的套接字中的数据块收集，并生成报文段的过程叫多路复用（封装数据）；把报文段的数据正确交付到对应的套接字叫做多路分解（解封和交付）
2. 提供可靠数据传输，以及拥塞控制等功能（TCP）

## UDP

UDP（用户数据报协议），和 TCP 协议一样用于处理数据包，是一种无连接的协议。通常适用于允许丢失、但对实时性要求很高的功能。

### UDP 特点

1. **无连接**

UDP 不需要和 TCP 一样在发送数据前进行三次握手建立连接的，想发数据就可以开始发送了。并且也只是数据报文的搬运工，不会对数据报文进行任何拆分和拼接操作。
具体来说就是：
- 在发送端，应用层将数据传递给传输层的 UDP 协议，UDP 只会给数据增加一个 UDP 头标识下是 UDP 协议，然后就传递给网络层了
- 在接收端，网络层将数据传递给传输层，UDP 只去除 IP 报文头就传递给应用层，不会任何拼接操作
   
2. **传输方式多样**

UDP 不止支持一对一的传输方式，同样支持一对多，多对多，多对一的方式，也就是说 UDP 提供了单播，多播，广播的功能。
   
3. **面向报文**
   发送方的 UDP 对应用程序交下来的报文，在添加首部后就向下交付 IP 层。UDP 对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界。因此，应用程序必须选择合适大小的报文
   
4. **不可靠性**
   首先不可靠性体现在**无连接**，通信都不需要建立连接，想发就发，这样的情况肯定不可靠。
   并且收到什么数据就传递什么数据，并且也不会备份数据，发送数据也**不会确定对方是否已经正确接收到数据**。
   再者网络环境时好时坏，但是 UDP 因为**没有拥塞控制**，一直会以恒定的速度发送数据。即使网络条件不好，也不会对发送速率进行调整。
   这样实现的弊端就是在网络条件不好的情况下可能会导致丢包，但是优点也很明显，在某些实时性要求高的场景（比如电话会议）就需要使用 UDP 而不是 TCP。
   
5. **高效**
    UDP 头部包含了以下几个数据：
    
    ![image-20221017183928534](https://blog-img-1307852525.cos.ap-chengdu.myqcloud.com/img/image-20221017183928534.png)

  - 两个十六位的端口号，分别为源端口（可选字段）和目标端口
  - 整个数据报文的长度
  - 整个数据报文的检验和（IPv4 可选字段），该字段用于发现头部信息和数据中的错误

  > 检验和：将所有的字相加，得到的字如果溢出就回卷（去掉几个开头的位），然后取其反码作为检验和。
  > 在验证时用检验和和所有字的和相加，如果不全为1就说明有差错。

  因此 UDP 的头部开销小，只有 8 字节，相比 TCP 的至少 20 字节要少得多，在传输数据报文时是很高效的。

## TCP

TCP 的全称是传输控制协议是一种面向连接的、可靠的、基于字节流的传输层通信协议。TCP 是面向连接的、可靠的流协议（流就是指不间断的数据结构）。
TCP 应用场景： 效率要求相对低，但对**准确性**要求相对高的场景。因为传输中需要对数据确认、重发、排序等操作，相比之下效率没有 UDP 高。例如：文件传输（准确高要求高、但是速度可以相对慢）、接受邮件、远程登录

### TCP 特点

1. **面向连接**
   面向连接，是指发送数据之前必须在两端建立连接。建立连接的方法是“三次握手”，这样能建立可靠的连接。建立连接，是为数据的可靠传输打下了基础。
1. **仅支持单播传输**
   每条 TCP 传输连接只能有两个端点，只能进行点对点的数据传输，不支持多播和广播传输方式。
1. **面向字节流**
   TCP 不像 UDP 一样那样一个个报文独立地传输，而是在不保留报文边界的情况下以字节流方式进行传输。
1. **可靠传输**
   对于可靠传输，判断丢包、误码靠的是 TCP 的段编号以及确认号。TCP 为了保证报文传输的可靠，就给每个包一个序号，同时序号也保证了传送到接收端实体的包的按序接收。然后接收端实体对已成功收到的字节发回一个相应的确认(ACK)；如果发送端实体在合理的往返时延(RTT)内未收到确认，那么对应的数据（假设丢失了）将会被重传。
1. **提供拥塞控制**
   当网络出现拥塞的时候，TCP 能够减小向网络注入数据的速率和数量，缓解拥塞。
1. **提供全双工通信**
   TCP 允许通信双方的应用程序在任何时候都能发送数据，因为 TCP 连接的两端都设有缓存，用来临时存放双向通信的数据。当然，TCP 可以立即发送一个数据段，也可以缓存一段时间以便一次发送更多的数据段（最大的数据段大小取决于 MSS）

### TCP 报文段

![](https://pic.imgdb.cn/item/62348f555baa1a80ab774d02.jpg)
TCP 报文结构如上所示：

- 32 比特的序号（seq）和确认号（ack），这两个是报文中确定传输最重要的部分
- 16 比特的接收窗口，用于流量控制
- 标志字段，包括 ACK、SYN、FIN 等多个用于标识状态的字段。常用的标志位：
  - `SYN`(synchronous)： 发送/同步标志，用来建立连接，和下面的第二个标志位 ACK 搭配使用。连接开始时，SYN=1，ACK=0，代表连接开始但是未获得响应。当连接被响应的时候，标志位会发生变化，其中 ACK 会置为 1，代表确认收到连接请求，此时的标志位变成了 SYN=1，ACK=1。
  - `ACK`(acknowledgement)：确认标志，表示确认收到请求。
  - `PSH`(push) ：表示推送操作，就是指数据包到达接收端以后，不对其进行队列处理，而是尽可能的将数据交给应用程序处理；
  - `FIN`(finish)：结束标志，用于结束一个 TCP 会话；
  - `RST`(reset)：重置复位标志，用于复位对应的 TCP 连接。
  - `URG`(urgent)：紧急标志，用于保证 TCP 连接不被中断，并且督促中间层设备尽快处理。
- 首部字段，指示 TCP 首部长度（不包括数据），一般是 20 字节，但是可变；
- 数据字段，由于 MSS（最大报文段长度） 的限制，数据字段一般不会大于`1500-20-20=1460`字节

#### 序号和确认号

TCP 把数据看作是一个无结构的、有序的字节流；因此序号标识的是数据的**字节**，而不是报文段。
报文中的序号（seq）通常是报文中数据段的段首字节位置；
![](https://pic.imgdb.cn/item/623493275baa1a80ab80f873.jpg)

> 比如有一个 500000 字节的文件，每个报文段数据为 1000 字节，那么 seq 就分别是 0、1000、2000 直到 499000

确认号表示期望从对方主机收到的下一个字节序号。

> 比如两个主机 A 和 B，主机 A 已经收到了来自主机 B 的编号为 0~535 的字节，因此主机 A 再次给主机 B 发送的 ack 就是 536，表示期望收到第 536 号字节之后的数据；
> 另外，如果主机 B 给主机 A 发送的不是 536 之后的，主机 A 仍会继续发送 ack=536，直到接收到 536 为止，再继续请求下一个最前面的字节序号；这也是后面 TCP 可靠数据传输的原理之一，即`累计确认`

### TCP 的可靠数据传输

TCP 可靠数据传输主要通过重传机制实现；其中导致 TCP 进行重传的条件主要有两个：

1. 定时器超时（超时重传）
2. 连续收到三个 ack（快速重传）

#### 超时重传

TCP 仅在刚发送第一个报文段时启动**一个**定时器，在定时器到期并且仍没有收到有效的 ACK 时，就会重新发送具有最小序号的报文段（即最早发送的那个）。
由于超时时间过长或过短都会导致传输数据出现异常（详见计网 P162），因此每一次重传都会将超时时间间隔设置为前一次的 2 倍；如果有新的重传事件发生（比如收到了 3 个冗余 ack），就会重新计算超时时间。

#### 快速重传

当发送方连续收到 3 个相同的 ack 时，将会在定时器到期之前就重传这个报文段。
收到冗余 ack 的原因是 TCP 会在不同的情况下发送可能不同于平常的 ack，规则如下：（都是指接收方）

| 事件                                         | 动作                                                                       |
| -------------------------------------------- | -------------------------------------------------------------------------- |
| 收到正常顺序的数据，并且之前没有缺漏         | 延迟 500ms 发送 ack，即如果下一个报文段 500ms 内没有到达，就发送这个的 ack |
| 收到比期望序号大的报文段，即`seq > ack`      | 说明中间有缺失，会继续发送缺失部分的 ack                                   |
| 收到填补缺失的报文段，填补之后前面都已经完整 | 从整个接收区的末尾字节继续发送 ack，即完全填充之后就又正常发送 ack         |

因此，收到冗余 ack 的原因是**报文段缺失**。
一旦发送方收到连续 3 个相同的 ack，就会进行快速重传，即把缺失的报文段再发一次，以弥补接收方的缺失。

> 至于为什么是3个，其实是一种统计规律的结果。即如果出现了3个冗余ACK可能是乱序或丢包导致的，但是丢包一定会产生3个冗余ACK，而乱序可能会产生1、2、3个不等的。
>
> 可以看一个回答：https://www.zhihu.com/question/21789252

这部分的图可以参考 计网 P164

---

快速重传并不是处理丢包最完美的重传方式。它有一个很大的问题是，如果出现三个重复的ACK，那应该从这个ACK开始将之后的都重新发送，还是只发送丢包的那个？

后者明显效率更高，但是需要知道具体是哪个位置发生了丢包。因此就有了一种**SACK重传**；这种方式需要在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将已收到的数据的信息发送给「发送方」**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**。

![](https://pic1.imgdb.cn/item/6368daca16f2c2beb1231c3c.jpg)

### TCP 流量控制

TCP的流量控制主要是基于滑动窗口机制。TCP在发送端和接收端都设置了一个滑动窗口，用于可以保证一次性接收多组数据，而不是一收一发。窗口大小就是指**无需等待确认应答，而可以继续发送数据的最大值**。

发送方窗口：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/16.jpg?)

发送方可以随时发送#3内的数据。当收到接收方的ACK时，则会缩小#2的左边界，增大#1的右边界，相当于窗口向右移动

![32 ~ 36 字节已确认](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/18.jpg)

接收方窗口：

![接收窗口](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/20.jpg)

接收窗口的大小和发送窗口的大小不同时相等。即他们在大多数时刻是相等的；接收方通过告知发送方当前自己的接收窗口大小来使得发送方减少发送窗口大小，相当于减少了发送数据的量；当他们同时做出改变时，两者的大小就是相等的；但是如果发送方还没来得及缩小或扩大窗口，那就是不相等，不过稍后还是会趋向相等。

通常情况下，双方的滑动窗口大小可能会“一伸一缩”的变动，但是最大的大小不会改变。

![流量控制](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/21.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)

但是有特殊情况是，如果接收方因为应用层的原因不能及时取走缓冲区内的数据，那么接收方的滑动窗口大小就可能变得越来越小。这时为了防止发送方仍然发送很多数据导致接收方接收不到的情况，就需要让发送方通知接收方减少发送窗口的大小，最终甚至可能减为0

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/22.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)


接收窗口的空闲区间大小用`rwnd`表示，表示缓存区中的**空闲空间**。
当接收方收到数据时，会把rwnd放在回复给发送方的报文段中。发送方收到接收方的rwnd之后，便可以通过这个值确定自己本次要发送多少数据，保证自己发送的数据量不会导致rwnd被充满。
发送方要保证发送的数据不会使得 rwnd 变为 0；同时如果 rwnd 变为 0 也并不是完全停止发送，而是会继续发送一个字节的报文段，用于获取新的 rwnd 值。
详见计网 P165

### TCP 拥塞控制

拥塞控制不等同于流量控制。虽然两者都是通过控制发送的数据量来影响传输，但是拥塞控制主要解决的是重传导致的恶性循环（拥堵导致丢包，丢包导致重传，越重传越拥堵），而流量控制通常不会考虑到重传问题。

TCP的拥塞控制实际上是一种端到端的拥塞控制，即，网络层没有提供任何关于拥塞的信息，拥塞与否主要依靠TCP自己判断，比如三次冗余ack等方式。

TCP 拥塞控制就是控制拥塞窗口`cwnd`，限制**发送**方在未确认时能发送的数据量。因此接受方中未被确认的数据量不会大于`min{cwnd,rwnd}`。其实也就是说发送方要发送的数据量不能大于这两个的最小值。

> 注意rwnd和cwnd的区别：
> rwnd：流量控制机制，由接收端的缓存空间剩余量决定，由接收端发送给发送端
> cwnd：拥塞控制机制，由发送端跟踪并控制，可以由发送端直接改变

TCP 的拥塞控制机制主要是以下三种机制：

- 慢启动
- 拥塞避免
- 快速恢复

拥塞控制的特点：线性增加（拥塞避免或快速恢复的线性增加）、乘性减少（一旦有冗余 ack 就把阈值砍半）

> 注意拥塞控制中的速度单位 MSS/RTT ，即一次收发时间内发送多少个最大报文段长度。

#### 慢启动

慢启动流程：

1. TCP 连接刚开始时`cwnd`值通常被设为 1 个 MSS（最大报文段长度），然后每当收到一个确认时就指数增加，变成每次发送 2、4、8.....个 MSS；
2. 慢启动的停止条件和情况有三种：
  1. 当出现一次**超时重传**时，就立即停止这种增长，取当前发送的 MSS 值的一半作为`ssthresh`值，即“阈值”（比如到一次发送 8 个 MSS 时出现超时，就设置 ssthresh = 4），并且把cwnd重设为1，**重新开始慢启动**。
  2. 当已经设置了ssthresh值，并且慢启动又到达了这个值，就会进入**拥塞避免**
  3. 当出现**三个冗余ack**时，进入快速恢复阶段。

#### 拥塞避免

进入拥塞避免时，由上面可以知道此时cwnd应该是刚到达ssthresh，即阈值的一半。

1. 在拥塞避免阶段，增长变成线性，即从慢启动确定的阈值开始，一次只增加一个 MSS。
2. 结束拥塞避免阶段也有两种情况：
  1. 当出现一次**超时重传**时，和慢启动一样，cwnd被重设为1，重新慢启动。
  2. 当出现一次**快速重传**时（即三个冗余 ack），就立即停止增长，并类似的设置阈值为当前值的一半。比如这次到 12MSS 时出现重传，就设置阈值为 6；然后进入快速恢复阶段

#### 快速恢复

快速恢复启动的时候有两种情况：
1. 拥塞避免阶段结束，刚刚出现了一次快速重传
2. 慢启动结束，刚刚出现了一次快速重传

因此不管是哪种情况进入，都是因为快速重传的出现。快速恢复就是为了处理这种快速重传。

快速恢复不是一个必须项，并且快速恢复有两个版本：

- Tahoe，已废弃的版本，区别是拥塞避免出现冗余 ack 之后也会直接将 cwnd 设置为 1，即任何异常都会之间置为 1
- Reno，就是当前采用的方法；出现冗余 ack 并不会直接置为 1，而是从`(ssthresh / 2) + 3`开始继续拥塞避免。上面的阈值设置为 6，就从 9MSS 开始进入拥塞避免阶段，即匀速增长。

在快速恢复中如果再次出现超时的情况，就执行在上面两个中一样的步骤，即cwnd重置为1，并进入慢启动重新走一次流程。

### TCP 三次握手

![](https://pic.imgdb.cn/item/6234ab885baa1a80abb8eabe.png)

步骤： 
0. 初始两端都处于 closed 状态。
1. 客户端向服务端发送一个不含有有效载荷的 TCP 报文段；标志位`SYN=1`，seq 设置一个随机的值作为初始序号（设为 x）；发送之后客户端进入`SYN-SENT`阶段，发送时服务端处于`LISTEN`阶段。
2. 服务端收到该报文，分配缓存和变量，根据 seq 值确定自己要开始接收的序号（即 ack 值），然后给客户端告知自己的 seq 值，标志位`SYN=1, ACK=1`。同理服务端发送后也立即进入`SYN-RECEIVED`阶段；
   注意服务器返回的`ack = x + 1`，是因为`SYN`会消耗一个序列号；**凡是需要对端确认的，一定消耗 TCP 报文的序列号**，下一个连接的 ack 为 y+1 也是这个原因。同时还会发送自己经过分配得到的 seq 值（设为 y）。这段报文同样没有有效载荷，被称为`SYNACK报文段`
3. 客户端收到，同样给连接分配缓存和变量；将自己的 seq 设置为`x+1`，即上一步服务器的 ack 值，表示自己从这里开始发送；随后令自己的`ack = y + 1`，即服务器的 seq 值下一个，标志位`ACK=1,SYN=0`。客户端发送后进入`ESTABLISHED`阶段，此时客户端已经准备好；服务端接收到之后也会进入`ESTABLISHED`阶段；当两者都进入，连接成功，开始发送数据。
   另外这个请求可以携带有效载荷，同时因为连接已经建立，`SYN=0`

> 一定要三次握手的原因：
> 为了确认双方的接收能力和发送能力都正常
> 如果是用两次握手，则会出现下面这种情况：
> 如客户端发出连接请求，但因连接请求报文丢失而未收到确认，于是客户端再重传一次连接请求。后来收到了确认，建立了连接。数据传输完毕后，就释放了连接，客户端共发出了两个连接请求报文段，其中第一个丢失，第二个到达了服务端，但是第一个丢失的报文段只是在某些网络结点长时间滞留了，延误到连接释放以后的某个时间才到达服务端，此时服务端误认为客户端又发出一次新的连接请求，于是就向客户端发出确认报文段，同意建立连接，不采用三次握手，只要服务端发出确认，就建立新的连接了，此时客户端忽略服务端发来的确认，也不发送数据，则服务端一致等待客户端发送数据，浪费资源。

概括一下就是：

1. 第一次握手： 客户端向服务端发送连接请求报文段。该报文段中包含自身的数据通讯初始序号。请求发送后，客户端便进入 `SYN-SENT` 状态。
1. 第二次握手： 服务端收到连接请求报文段后，如果同意连接，则会发送一个应答，该应答中也会包含自身的数据通讯初始序号，发送完成后便进入 `SYN-RECEIVED` 状态。
1. 第三次握手： 当客户端收到连接同意的应答后，还要向服务端发送一个确认报文。客户端发完这个报文段后便进入 `ESTABLISHED` 状态，服务端收到这个应答后也进入 `ESTABLISHED` 状态，此时连接建立成功。

> seq的起始序号通常不会从0开始，而是随机取一个序列号。主要原因是防止历史报文被下一个相同四元组的连接接收。
> 虽然通常情况下，通过四次挥手断开的连接由于在最后等待了2MSL的时间，历史报文必然已经消失；但是不是所有的连接都是通过四次挥手断开的。
> 假如服务端由于物理原因重启，导致客户端发送的数据没有被正确接收，连接也没有被四次握手断开，那么这时就会有一些残留的历史报文留在发送的路途上。假如下一次连接的seq不随机取，而是仍然选择某个初始值，就会导致收到历史报文，把它当作客户端本次连接发送的报文处理，导致错误
>
> ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/network/tcp/isn%E7%9B%B8%E5%90%8C.png)
>
> 如上图，最后一个红色的发送就是上次连接的历史报文。这里服务端的接收就会导致它发送的ack异常，导致后续请求都出问题。
>
> 每次初始化序列号不一样能够很大程度上避免历史报文被下一个相同的连接接收，当然也不是100%避免。
>
> 客户端和服务端的初始化序列号是一个ISN算法生成的，随机数是会基于时钟计时器递增的，基本不可能会随机成一样的初始化序列号。

### TCP 四次挥手

![](https://pic.imgdb.cn/item/6234b0a55baa1a80abc43d47.jpg)

1. 第一次挥手： 客户端会发送一个 FIN 报文，报文中会指定一个序列号。此时客户端处于 `FIN_WAIT1` 状态。
   即发出连接释放报文段（FIN=1），并停止再发送数据，主动关闭 TCP 连接，进入`FIN_WAIT1`（半关闭）状态，等待服务端的确认。

2. 第二次挥手：服务端收到 FIN 之后，会发送 ACK 报文，且把客户端的序列号值 +1 作为 ACK 报文的序列号值，表明已经收到客户端的报文了，此时服务端处于 `CLOSE_WAIT `状态。
   即服务端收到连接释放报文段后即发出确认报文段（ACK=1），服务端进入`CLOSE_WAIT`（关闭等待）状态，此时的 TCP 处于半关闭状态，**客户端到服务端的连接释放**。
   客户端收到服务端的确认后，进入`FIN_WAIT2`（终止等待 2）状态，等待服务端发出的连接释放报文段。

3. 第三次挥手：如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且指定一个序列号。此时服务端处于 `LAST_ACK `的状态。
   即服务端没有要向客户端发出的数据，服务端发出连接释放报文段（FIN=1，ACK=1），服务端进入`LAST_ACK`（最后确认）状态，等待客户端的确认。

4. 第四次挥手：客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答，且把服务端的序列号值 +1 作为自己 ACK 报文的序列号值，此时客户端处于 `TIME_WAIT` 状态。需要过一阵子以确保服务端收到自己的 ACK 报文之后才会进入 `CLOSED` 状态，服务端收到 ACK 报文之后，就处于关闭连接了，处于 `CLOSED` 状态。
   即客户端收到服务端的连接释放报文段后，对此发出确认报文段（ACK=1），客户端进入`TIME_WAIT`（时间等待）状态。
   此时 TCP 未释放掉，**需要经过时间等待计时器设置的时间 2MSL 后**，客户端才进入 CLOSED 状态。（1MSL 大概是 30s 左右，这是Linux的数据）

---

那为什么需要四次挥手呢？

> 因为当服务端收到客户端的 SYN 连接请求报文后，可以直接发送 SYN+ACK 报文。其中 ACK 报文是用来应答的，SYN 报文是用来同步的。但是关闭连接时，当服务端收到 FIN 报文时，很可能并不会立即关闭 SOCKET，所以只能先回复一个 ACK 报文，告诉客户端，“你发的 FIN 报文我收到了”。**只有等到我服务端所有的报文都发送完了**，我才能发送 FIN 报文来确认关闭，因此不能一起发送，故需要四次挥手。

---

简单来说就是以下四步：

1. 第一次挥手： 若**客户端认为数据发送完成**，则它需要向服务端发送连接释放请求。
1. 第二次挥手：服务端收到连接释放请求后，会告诉应用层要释放 TCP 链接。然后会发送 ACK 包，并进入 `CLOSE_WAIT` 状态，此时表明客户端到服务端的连接已经释放，**不再接收客户端发的数据**了。但是因为 TCP 连接是双向的，所以服务端仍旧可以发送数据给客户端。
1. 第三次挥手：服务端如果此时**还有没发完的数据**会继续发送，完毕后会向客户端发送连接释放请求，然后服务端便进入 `LAST-ACK` 状态。
1. 第四次挥手： 客户端收到释放请求后，向服务端发送确认应答，此时客户端进入 `TIME-WAIT` 状态。该状态会持续 2MSL（**最大段生存期**，指报文段在网络中生存的时间，超时会被抛弃） 时间，若该时间段内没有服务端的重发请求的话，就进入 `CLOSED` 状态。当服务端收到确认应答后，也便进入 `CLOSED` 状态。

TCP 使用四次挥手的原因是因为 TCP 的连接是**全双工**的，所以**需要双方分别释放到对方的连接**，单独一方的连接释放，只代表不能再向对方发送数据，连接处于的是半释放的状态。

最后一次挥手中，客户端会等待一段时间再关闭的原因，主要有两个原因：

1. **防止发送给服务器的确认报文段丢失或者出错**，从而导致服务器端不能正常关闭。
2. 防止下一次建立连接时，历史报文再次发送。比如挥手之前的某个报文由于时间原因耽搁了，如果不等这2MSL，那么有可能紧接着的下一次连接就会收到这个报文，导致传输的数据出错。等待2MSL一定可以使本次连接内的所有报文都消失掉，避免出现历史报文重新发送的问题。

至于为什么值是2MSL，并且单位为什么是MSL而不是RTT，主要是这几个原因：

1. MSL而不是别的单位：因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 `TTL` 字段，是 IP 数据报可以经过的最大路由数。**MSL 应该要大于等于 TTL 消耗为 0 的时间**，以确保报文已被自然消亡。
2. 为什么是2倍：网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以**一来一回需要等待 2 倍的时间**。也就是说比如在FIN_WAIT2的最后一步，也就是最后一个报文没有被接收方收到，就会触发超时重发FIN报文，另一方接收到 FIN 后，会重发 ACK 给被动关闭方， 一来一去正好 2 个 MSL。

# 网络层

网络层运行在传输层之下，从结构上分为数据平面（IP）和控制平面（SDN），其主要的功能有两个：

- 转发，是数据平面的唯一功能，即主机和主机、主机和路由器、路由器和路由器之间转发分组；绝大部分的转发在路由器上完成
- 路由选择，控制平面的主要功能，即选择合适的路径、转发方式

网络层的主要作用是：**实现主机与主机之间的通信，也叫点对点（end to end）通信。**

## IP（IPv4）

### IP 数据报

![](https://pic.imgdb.cn/item/623595a65baa1a80ab118e12.png)

- 版本：指 IP 协议的版本，占 4 位，如 IPv4 和 IPv6；
- 首部位长度：表示 IP 首部长度，占 4 位，最大数值位 15；
- 总长度：表示 IP 数据报总长度，占 16 位，最大数值位 65535；
- 生存时间（TTL）：表示 IP 数据报文在网络中的寿命，占 8 位；
- 协议：表明 IP 数据所携带的具体数据是什么协议的，如 TCP、UDP。

### IP 编址

好比一个人出行需要目的地和出发地一样，IP地址起到了在网络世界中定址的作用

IP 地址采用等分十进制编码，即把本来的四个二进制字节写作类似`xxx.xxx.xxx.xxx`的格式。

#### 子网

网络中并不是所有的设备都分散在网络各处，而是会组成一个个的小块，互联这些小块中的主机接口和路由器接口的网络叫做**子网**。每个子网前面一部分的编址相同，只有后面一小部分的编址不同，用于区分子网内的主机；

![](https://pic.imgdb.cn/item/62359a035baa1a80ab1bfec6.jpg)

通常写作`a.b.c.d/x`格式，其中`/x`称为**子网掩码**，用于说明前 x 位是子网中具有相同前缀的位数，也叫做**前缀**；

- 前缀用来标识子网，也被叫做地址的网络部分；
- 前缀之后的部分用来标识子网中的主机

外部连接子网时，并不需要直到每个确定的设备 IP，而是只需要知道前缀，将请求发给网关路由器即可。

#### 地址分类

以前，IP 地址的网络部分的长度被限制只能是 8、16、24 比特的一种，即掩码只能是 8、16 或 24。因此，网络部分长度为 8/16/24 比特的网络分别被成为 A/B/C 类网络：

![](https://pic.imgdb.cn/item/62359b5b5baa1a80ab1f39f1.png)
![](https://pic.imgdb.cn/item/6235a03d5baa1a80ab2a302e.png)

IP 地址可根据主机号和网络号所占字节分为 ABCDE 类：

- A 类地址:网络号占 1 个字节。网络号的第一位固定为 0。
- B 类地址：网络号占 2 个字节。网络号的前两位固定为 10。
- C 类地址：网络号占 3 个字节。网络号的前三位固定位 110。
- D 类地址：前四位是 1110，用于多播(multicast)，即一对多通信。D和E类地址都是没有主机号的，因此不能用于特定的主机间一对一传输
- E 类地址：前四位是 1111，保留为以后使用。
  其中，ABC 三类地址为单播地址（unicast),用于一对一通信，是最常用的。

IP地址分类的最大好处是，主机解析到一个 IP 地址时候，解析其IP地址前几位就可以得出它是哪类地址.

后来提出了CIDR的概念。CIDR 是无类别域间路由选择的简称，即可以任意划定主机部分和网络部分的长度，用子网掩码作为标识指示第一部分的比特数；通过 CIDR，就不会有对网络号的位数限制，即不再有 A/B/C 类网络的划分。

就比如：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/15.jpg)

不同类型的网络拥有不同数量的主机和网络数。比如 A 类网络部分长度为 8，即最多只能有`2^8 - 2 = 254`个网络（全 1 和全 0 有特殊用处），但每个子网却有`2^24 - 2`台主机；其他的同理：
![](https://pic.imgdb.cn/item/62359c395baa1a80ab213a37.jpg)

> 特殊的 IP 地址：
>
> - `127.0.0.1`：回环地址。该地址指电脑本身
> - `10.x.x.x`、`172.16.x.x`～`172.31.x.x`、`192.168.x.x`：这些地址被用做内网中。用做私网地址，这些地址不与外网相连。
> - `0.0.0.0`：这个 IP 地址在 IP 数据报中只能用作**源**IP 地址，这发生在当设备启动时但又不知道自己的 IP 地址情况下。
> - `255.255.255.255`：广播地址，只能用作**目标**IP 地址，用于不知道自己 IP 的情况下寻找 DHCP 服务器时用
> - 主机号全为 0（`xxx.0.0.0`）：标识本子网
> - 主机号全为 1（`xxx.255.255.255`）：标识本子网下的全部主机

## IPV6

IPV6的特点：

1. 128位地址，采用8组4位16进制数表示，用冒号隔开
2. 可自动配置，即使没有 DHCP 服务器也可以实现自动分配IP地址
3. 去掉了包头校验和，简化了首部结构，减轻了路由器负荷

![IPv4 首部与 IPv6 首部的差异](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/31.jpg)

## 其他网络层技术

### DHCP

用于为主机动态配置IP地址。通常一个主机连接到网络获得IP地址的过程，就是执行DHCP的过程。

![DHCP 工作流程](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/36.jpg)

DHCP本质上是一个应用，所以你也可以说他是一个基于UDP之上的应用层协议。

这个过程的步骤：

1. 客户端首先发起 **DHCP 发现报文（DHCP DISCOVER）** 的 IP 数据报，由于客户端没有 IP 地址，也不知道 DHCP 服务器的地址，所以使用的是 UDP **广播**通信，其使用的广播目的地址是 255.255.255.255（端口 67） 并且使用 0.0.0.0（端口 68） 作为源 IP 地址。DHCP 客户端将该 IP 数据报传递给链路层，链路层然后将帧广播到所有的网络中设备。
2. DHCP 服务器收到 DHCP 发现报文时，用 **DHCP 提供报文（DHCP OFFER）** 向客户端做出响应。该报文仍然使用 IP 广播地址 255.255.255.255，该报文信息携带服务器提供可租约的 IP 地址、子网掩码、默认网关、DNS 服务器以及 **IP 地址租用期**。
3. 客户端收到一个或多个服务器的 DHCP 提供报文后，从中选择一个服务器，并向选中的服务器发送 **DHCP 请求报文（DHCP REQUEST**进行响应，回显配置的参数。
4. 最后，服务端用 **DHCP ACK 报文**对 DHCP 请求报文进行响应，应答所要求的参数。

### NAT

简单的来说 NAT 就是同个公司、家庭、教室内的主机对外部通信时，把私有 IP 地址转换成公有 IP 地址。

![NAT](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/38.jpg)

NAT的升级是NAPT，改用端口区分子网内的不同主机。

由于TCP和UDP区分连接的方式都包含源端口，因此相同的IP不同的端口会被视作是不同的请求。因此NAPT在转换私有IP内部的主机时，为每个内部请求创建一个不同的端口，这样就相当于不同的请求。

![NAPT](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/39.jpg)

### ICMP

ICMP 全称是 **Internet Control Message Protocol**，也就是**互联网控制报文协议**。

`ICMP` 主要的功能包括：**确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。**

在 `IP` 通信中如果某个 `IP` 包因为某种原因未能达到目标地址，那么这个具体的原因将**由 ICMP 负责通知**。

![ICMP 目标不可达消息](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/40.jpg)

# 链路层

## 以太网

以太网（英语：Ethernet）是为了实现**局域网**通信而设计的一种技术（是一种技术方案或者说是技术标准，并不是一种网络），它规定了包括物理层的连线、电子信号和介质访问层协议的内容。以太网是目前应用最普遍的局域网技术，取代了其他局域网标准如令牌环、FDDI和ARCNET。

链路层、物理层都属于以太网技术的范畴

以太网帧其实就是链路层对IP数据包的封装。

## 链路层寻址（MAC）

主机和路由器本身不具有链路层地址，是他们的网卡（网络适配器、网络接口）具有。链路层地址可以认为就是 MAC 地址。
MAC 地址为 6 字节，一旦被赋予就是**永久**的，一个 MAC 地址始终和网卡绑定，采用十六进制表示。
![MAC.jpg](https://i.loli.net/2021/12/02/G4P5bBIxHwOtup7.jpg)

> MAC 地址只在子网内生效；如果想要发送到外部，则只需要网关路由器输入端口的 MAC 地址，再由网关路由器进行 ARP 查询和转发。

## ARP 协议

ARP 协议协议(Address Resolution Protocol)，地址解析协议，它是用于实现**IP 地址到 MAC 地址的映射**。
ARP 协议是自学习、零配置的，其能够通过反复把最新的映射添加到维护的 ARP 表中，实现自动配置。

> ARP 协议既是网络层又是链路层的协议，是一个介于两者之间的协议。

ARP 协议流程如下：

1. 首先，每台主机、交换机都会在自己的 ARP 缓冲区中建立一个 ARP 列表，以表示 IP 地址和 MAC 地址的对应关系。
2. 当源主机需要将一个数据包要发送到目的主机时，会首先检查自己的 ARP 列表，是否存在该 IP 地址对应的 MAC 地址；如果有﹐就直接将数据包发送到这个 MAC 地址；如果没有，就向本地网段发起一个 ARP 请求的广播包，查询此目的主机对应的 MAC 地址。此 ARP 请求的数据包里，包括源主机的 IP 地址、硬件地址、以及目的主机的 IP 地址。
3. 网络中所有的主机收到这个 ARP 请求后，会检查数据包中的目的 IP 是否和自己的 IP 地址一致。如果不相同，就会忽略此数据包；如果相同，该主机首先将发送端的 MAC 地址和 IP 地址添加到自己的 ARP 列表中，如果 ARP 表中已经存在该 IP 的信息，则将其覆盖，然后给源主机发送一个 ARP 响应数据包，告诉对方自己是它需要查找的 MAC 地址。
4. 源主机收到这个 ARP 响应数据包后，将得到的目的主机的 IP 地址和 MAC 地址添加到自己的 ARP 列表中，并利用此信息开始数据的传输。如果源主机一直没有收到 ARP 响应数据包，表示 ARP 查询失败。

### RARP

RARP 协议正好相反，它是**已知 MAC 地址求 IP 地址**。它常常用于一些只预先配置了MAC地址，而没有获得IP地址的小型设备，比如打印机。

RARP有一个专属的RARP服务器，在这个服务器上注册设备的 MAC 地址及其 IP 地址。当有设备想要从自己的MAC地址获得对应的IP地址，就会类似ARP一样，广播并收到RARP服务器的响应，随后设置自己的IP地址。



# 从浏览器输入 url 到显示的过程

### 0. 连接网络

1. 主机生成 DHCP 请求报文，被放在具有 IP 广播地址（255.255.255.255）和源 IP（0.0.0.0）的 IP 数据报中
2. 将上一步的数据报放置在以太网帧，该帧具有`FF:FF:FF:FF:FF:FF`的广播 MAC 地址，然后广播出去
3. DHCP 服务器收到该广播，通过解封装抽取其 UDP 数据报，并给该主机分配一个 IP 地址，再次封装发回到主机的 MAC 地址（主机的 IP 位置但 MAC 已知且固定）
4. 主机收到该帧，解封装得知自己的 IP 地址，该主机的 DHCP 客户端记录下该主机的 IP，此时已经相当于“连接上网络”

### 1. 解析 URL

1. 首先会对 URL 进行解析，分析所需要使用的传输协议和请求的资源的路径。如果输入的 URL 中的协议或者主机名不合法，将会把地址栏中输入的内容传递给搜索引擎。如果没有问题，浏览器会检查 URL 中是否出现了非法字符，如果存在非法字符，则对非法字符进行转义后再进行下一过程。
2. 浏览器会判断所请求的资源是否在缓存里，如果请求的资源在缓存里并且没有失效，那么就直接使用，否则向服务器发起新的请求。
3. 主机生成 DNS 查询报文，获取到网关路由器的 IP 和 MAC 地址，准备向本地 DNS 服务器发送查询请求
4. 判断本地是否有该域名的 IP 地址的缓存，如果有则使用，如果没有则向本地 DNS 服务器发起请求。本地 DNS 服务器也会先检查是否存在缓存，如果没有执行 DNS 查询，可能会有迭代查询和递归查询两种方式。
5. 获取 MAC 地址： 当浏览器得到 IP 地址后，数据传输还需要知道目的主机 MAC 地址；

- 如果对应的 ip 和主机在同一个子网里，可以使用 ARP 协议获取到目的主机的 MAC 地址；
- 如果不在一个子网里，那么请求应该转发给网关，由它代为转发，此时同样可以通过 ARP 协议来获取网关的 MAC 地址，此时目的主机的 MAC 地址应该为网关的地址。（这一步其实在第 3 步已经完成）

### 2. TCP 和 HTTP 连接

1. 进行 TCP 三次握手
2. 如果连接是 HTTPS，就还需要一个 HTTPS 握手：
3. 发送 HTTP GET 请求，请求对应的 HTML 文档；
8. 浏览器响应，返回该 HTML 文件，浏览器接收到响应后，开始对 html 文件进行解析，开始页面的渲染过程。

### 3. 浏览器显示网页

1. 浏览器首先会根据 html 文件构建 DOM 树，对 HTML 中的标签进行词法解析。
2. **解析 css**：并通过一些 css 选择器，确定每个 dom 节点的样式；即使没有 css，浏览器内部也有自己的样式. 这个过程中会想创建 dom 树一样创建 CSSOM, CSSOM 的特点如下:
   - CSSOM 阻止任何东西渲染, 也就是说在 CSSOM 完全建立之前是不会展示界面的
   - CSSOM 在加载一个新页面时必须重新构建. 即使你的 CSS 文件被缓存了，也并不意味着这个已经构建好了的 CSSOM 可以应用到每一个页面。
   - CSSOM 是展示任何东西的必需品。在 CSSOM 构建之前，所有东西都不会展示，如果你阻塞了 CSSOM 的构建，CSSOM 的构建就会消耗更长的时间，这就意味着页面的渲染也需要更长的时间。
3. **布局（Layout）**，知道了每个节点的样式，还需要知道节点的位置：获取节点具体位置排版的过程叫做；主线程这时会通过像建立 dom 树一样的方式建立**Layout Tree**，每个节点上都记录元素的 xy 坐标、尺寸、边框等信息。layout 树是和展示在屏幕上的元素对应
4. **绘制（paint）**：还需要知道一定的绘制顺序。主线程会遍历 Layout Tree 生成**绘制记录表（Paint Record）**，然后后续按照记录表顺序进行绘制。
5. **栅格化（Rastering）**：把上面的 dom 树、绘制记录表、Layout Tree 等变成像素点展示在页面上
   - 这里介绍 chrome 栅格化方式的改进：现在采用的是合成方法，即对页面按一定规则分割成图层（Layer Tree），然后栅格化图层再进行拼接

这时主线程把信息传递给合成器线程，来把上面这些不同的表合成在一起

10. **分割图块（tiles）**：把图层分割成图块，每个图块都有一个栅格进程进行栅格化
11. **合成器帧（Frame）**：上一步栅格化之后，把每一部分存在 GPU 内存中；合成器线程收集（draw quads）的图块信息，拼接成合成器帧

接下来会通过 ipc 传输给浏览器进程中的 UI 线程

12. **最后渲染**：浏览器进程收到来自合成器帧拼接成的帧时，就会通过 GPU 渲染到屏幕上
13. **更新渲染**：当页面变化，就会生成新的合成器帧，然后继续按照 11、12 步渲染到页面上

![浏览器工作流程.png](https://i.loli.net/2021/12/02/I2sC6cwBHkgYESK.png)

# 网络安全相关

## CSP

内容安全策略( CSP )是一个额外的安全层，用于检测并削弱某些特定类型的攻击，包括跨站脚本 (XSS) 和数据注入攻击等
CSP 的实质就是白名单制度，开发者明确告诉客户端，哪些外部资源可以加载和执行，等同于提供白名单。
启动 CSP 的方法有两种:

- 通过 HTTP 头信息的 `Content-Security-Policy` 的字段

```
Content-Security-Policy: script-src 'self'; object-src 'none';
style-src cdn.example.org third-party.org; child-src https:;
```

- 另一种是通过网页的<meta>标签。

```html
<meta
  http-equiv="Content-Security-Policy"
  content="script-src 'self'; object-src 'none'; style-src cdn.example.org ; child-src https:"
/>
```

上面代码中，CSP 做了如下配置:

- 脚本：只信任当前域名
- `<object>`标签：不信任任何 URL，即不加载任何资源
- 样式表：只信任http://cdn.example.org
- 框架（iframe）：必须使用 HTTPS 协议加载
- 其他资源：没有限制

## XSS 攻击

XSS 即（`Cross Site Scripting`）中文名称为：跨站脚本攻击。
攻击者在网页插入一些 script 标签, 当用户浏览器加载到页面时会触发这段 script。攻击者会获取到比如 cookie 等信息，然后使用该信息来冒充合法用户
XSS 攻击最主要有如下分类：反射型、存储型、 DOM-based 型。

### 反射型

反射型 XSS 指的是恶意脚本作为网络请求的一部分。
主要是通过恶意链接, 当用户点击恶意链接时, 会跳转到攻击者预先准备的界面然后会返回攻击者准备的 js 脚本，该 js 脚本就在浏览器中执行了
比如输入:

```
http://sanyuan.com?q=<script>alert("你完蛋了")</script>
```

在服务器端会拿到 q 参数,然后将内容返回给浏览器端，浏览器将这些内容作为 HTML 的一部分解析，发现是一个脚本，直接执行，这样就被攻击了。
之所以叫它反射型, 是因为恶意脚本是通过作为网络请求的参数，经过服务器，然后再反射到 HTML 文档中，执行解析。和存储型不一样的是，服务器并不会存储这些恶意脚本。

### 存储型

主要是将恶意代码上传或存储到服务器中，下次只要受害者浏览包含此恶意代码的页面就会执行恶意代码。
因此存储型 XSS 的攻击步骤如下：

1. 攻击者将恶意代码提交到目标网站数据库中。
2. 用户打开目标网站时，网站服务器将恶意代码从数据库中取出，然后拼接到 html 中返回给浏览器中。
3. 用户浏览器接收到响应后解析执行，那么其中的恶意代码也会被执行。
4. 那么恶意代码执行后，就能获取到用户数据，比如上面的 cookie 等信息，把该 cookie 发送到攻击者网站中，那么攻击者拿到该 cookie 然后会冒充该用户的行为，调用目标网站接口等违法操作。

这种攻击常见于带有用户保存数据的网站功能，如论坛发帖、商品评论、用户私信等

### DOM-based

DOM XSS 是基于文档对象模型的 XSS。一般情况下不需要经过服务端，是出现于前端的问题，比如直接将用户的输入通过`innerHTML`或者`document.write`打印在页面上，就有可能执行恶意代码。

恶意输入的来源可能有：

- 用于输入的地方，比如 input、textarea
- url 栏，js 脚本可能会检测 url 的变化并把其中的某些参数取出来直接插入 dom

### XSS 的预防

详见https://tech.meituan.com/2018/09/27/fe-security.html

XSS 主要是要预防恶意代码的执行，即：

1. `innerHTML`的使用
   最主要的方式是对后端返回的数据，尤其是字符串进行转义。因为如果使用原本返回的字符，有可能导致被插入`<script>`脚本：

```js
const res = await fetch("/...");
const text = await res.json(); // 比如说这里的text是 `<script>alert('xss')</script>`

document.getElementById("test").innerHTML = text;

// html
<div>
  <script>alert('xss')</script>
</div>; // 这里就会执行该段恶意代码
```

比较好的方式是将发来的字符串转码，再插入 dom，但是转码之后可能导致显示异常，或者无法获取到正常的输出，应该尽量避免转码的方式。
或者根本就不使用`innerHTML`方法，在框架中表现为不使用`v-html/_dangerouslySetInnerHTML`直接转成 html 的方法，就可以有效避免。

2. `<a>`标签的`href`属性，要注意不能携带`'javascript:xxx'`这样会导致直接执行 js 的 url；要禁止以 `javascript:` 开头的链接，或者直接选择白名单形式，只允许`http: https:`才可以作为 href 属性。

3. 对于 js，要小心能直接运行字符串代码的函数，比如`eval()`、`setTimeout()`、`setInterval()`，或者能直接在 html 属性中运行 js 代码的事件监听`location`、`onclick`、`onerror`、`onload`、`onmouseover` 等

4. 过滤用户输入，即过滤用户在表单等地方输入的字符，不仅是前端要过滤非法字符，同时存储到数据库或者读取数据时也要过滤，或者采用第一种的转码方式。

5. 对 cookie 添加`HttpOnly`字段，不允许 js 读取，直接从源头上防止。

## CSRF 攻击

### 原理解释

跨站请求伪造（Cross-site request forgery），也被称为 one-click attack 或者 session riding，通常缩写为 CSRF 或者 XSRF， 是一种挟制用户在当前已登录的 Web 上执行非本意的操作的攻击方法。  
简单来说，攻击者诱导你登录一个跟你想登录的网站很类似的网站, 该网站可以利用 form 表单或者其他方式，向具有你信息的网站发送请求，网站的接口请求格式一般很容易获取到，请求会自动携带上网站的 cookie 信息，即你的身份验证信息
举个栗子
比如原先你的操作是获取你有多少钱, 这里使用的是 GET 请求

```
http://www.mybank.com/userdata?toBankId=11&money=1000
```

危险网站 B，它里面有一段 HTML 的代码如下：

```html
<img src="http://www.mybank.com/userdata?toBankId=11&money=1000" />
```

当你登录 A 的时候, 同时打开了 B 网站（不登出A的时候打开B，具体来说是A上的cookie等信息没有过期），浏览器会在B网站上向A网站发出一个请求，用于请求图片。这种情况比较多见，在一个网站上请求另一个服务器上的资源，比如图片、json等，都是合法的。因此关键在于这里获取了cookie。

当B网站发送这个请求后，你的浏览器会视作向A服务器发送一个请求，于是会带上你的银行网站 A 的 Cookie 发出 Get 请求，去获取资源`http://www.mybank.com/userdata?toBankId=11&money=1000`，结果银行网站服务器收到请求后，认为这是一个更新资源操作（转账操作），所以就立刻进行转账操作

这个过程中，用户其实是进入了一个恶意网站B，而这个网站可能是通过某些方式诱导用户点入的，比如广告、邮件等。一旦用户点进去这样的请求就会被发送，然后盗取用户的cookie。

再举个栗子
比如银行使用 POST 方法更新数据

这时危险网站就可以通过表单提交的方式伪造数据，流程和上面一样。总之只要用户点击了这个链接，浏览器携带了cookie去发送请求，就有csrf的风险。

```html
<form method="POST" name="transfer" action="http://www.myBank.com/userdata">
  <input type="hidden" name="toBankId" value="11" />
  <input type="hidden" name="money" value="1000" /> 　　　　　　
</form>
```

注意这个过程中，csrf攻击全称没有获取cookie，也没有执行任何脚本，只是想办法构造了请求，让浏览器自己携带cookie发送信息。

### 防范手段

CSRF攻击是源于WEB的隐式身份验证机制。WEB的身份验证机制虽然可以保证一个请求是来自于某个用户的浏览器，但却无法保证该请求是用户批准发送的（可能是别人代发送的）。

CSRF方式方法很多样，但总的思想都是一致的，就是**在客户端页面增加伪随机数**。对请求来说，其实就是添加一个用于防伪的字段，让服务端能通过校验来确定是不是用户发来的请求。

1. token机制，由服务端生成一个 token，返回给前端，在每次发送请求中，在参数中额外参加一个参数，例如 `csrf_token` , 服务端每次校验时对比 `csrf_token` 与服务端存储的值。由于token可能存在于http字段或存储在localstorage中，第三方网站一定获取不到，因此可以保证安全。
2. 验证码，即现在最常见的图片验证码，用户必须输入一个随机生成的验证码才能发送请求，没有这个验证码字段就不能生效。这样的话，恶意网站肯定无法伪造这个验证码，也就不能攻击。
3. Referer检查，根据 HTTP 协议，在 HTTP 头中有一个字段叫 `Referer`，记录了该 HTTP 请求的来源地址。可以借助来判断请求来源, 不是安全的就排除。在跨域中提到的Origin字段也可以起到这个效果
4. 启用Samesite属性。由于恶意网站作为第三方，向原网站发送请求时要发送cookie，而samesite属性就是用于控制跨站的请求（恶意网站B向A服务器发送，而不是A网站向A服务器发送）是否发送cookie的。如果设置为lax或strict，就可以保证不会随意发送cookie


